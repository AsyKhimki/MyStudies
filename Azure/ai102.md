<h1> Azure AI Engineer Associate </h1>

**Reference**
1. [Study Guide](https://learn.microsoft.com/en-gb/credentials/certifications/resources/study-guides/ai-102)
2. [Prompt engineering techniques](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/prompt-engineering?tabs=chat)

**Questions**
1. Prompt Flow based applications 

   
<h2> 1. Develop generative AI apps in Azure </h2>

| Unit  | Topic   | Section       | Notes  |
| :---    | :---   | :---     | :---     |
|  Plan and prepare to develop AI solutions on Azure | [Introduction](https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/1-introduction) | |**Azure AI Foundry** - a comprehensive platform for AI development on Microsoft Azure.|
||[What is AI](https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/2-what-is-ai)||- **Agents:** Generative AI applications that can respond to user input or assess situations autonomously, and take appropriate actions <br> - **Information extraction**: The ability to use computer vision, speech, and natural language processing to extract key information from documents, forms, images, recordings, and other kinds of content.<br> **Multi-modal models (language)** are able to handle image or speech prompts and respond by generating text, code, speech, or images|
||[Azure AI Services](https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/3-azure-ai-services)||- [List of Azure AI services](https://learn.microsoft.com/en-us/azure/ai-services/what-are-ai-services#available-azure-ai-services?azure-portal=true)<br> - **Azure AI services** a set of out-of-the-box prebuilt APIs and models that you can integrate into your applications <br> - To use Azure AI services, you create one or more Azure AI resources in an Azure subscription and implement code in client applications to consume them <br> - in most medium to large-scale development scenarios it's better to provision Azure AI services resources as part of an Azure AI Foundry project - enabling you to centralize access control and cost management, and making it easier to manage shared resources and build the next generation of generative AI apps and agents. <br> - Multi-service resource: encapsulates multiple AI services in a single Azure resource <br> **Examples** <br> - Azure AI services <br> - Azure AI Foundry <br> - Some services and models are available in only a subset of Azure regions |
||[Azure AI Foundry](https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/4-azure-ai-foundry)|- Azure AI Foundry projects <br> - Hub-based projects|- Azure AI Foundry is a platform for AI development on Microsoft Azure <br> - In Azure AI Foundry, you manage the resource connections, data, code, and other elements of the AI solution in projects.|
||[Developer Tools and SDKs](https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/5-tools-and-sdks)|- Development tools and environments <br> - The Azure AI Foundry for Visual Studio Code extension - GitHub and GitHub Copilot <br> - Programming languages, APIs, and SDKs <br> - GitHub and GitHub Copilot | - [Work with the Azure AI Foundry for Visual Studio Code extension (Preview)](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/get-started-projects-vs-code) <br> [GitHub Copilot in VS Code](https://code.visualstudio.com/docs/copilot/overview)|
||[Responsible AI](https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/6-responsible-ai)|- Fairness <br> - Reliability and safety <br> - Privacy and security <br> - Inclusiveness <br> - Transparency <br> - Accountability | - Consider fairness from the beginning of the application development process; carefully reviewing training data to ensure it's representative of all potentially affected subjects, and evaluating predictive performance for subsections of your user population throughout the development lifecycle. <br> - Users should be made fully aware of the purpose of the system, how it works, and what limitations may be expected.|
||[Excercise: explore AI Foundry](https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/7-exercise-explore-ai-foundry)|||
|Choose and deploy models from the model catalog in Azure AI Foundry portal|[Introduction](https://learn.microsoft.com/en-us/training/modules/explore-models-azure-ai-studio/1-introduction)||- The development process usually starts with an exploration and comparison of available foundation models to find the one that best suits the particular needs of your application. |
||[Explore the model catalog](https://learn.microsoft.com/en-us/training/modules/explore-models-azure-ai-studio/2-select-model)||**Can AI solve my use case?** <br> Catalogues of available language models <br> - [Hugging Face](https://huggingface.co/models): Vast catalog of open-source models across various domains.<br> - [GitHub](https://github.com/marketplace/models-github): Access to diverse models via GitHub Marketplace and GitHub Copilot.<br> - [Azure AI Foundry](https://ai.azure.com/catalog): Comprehensive catalog with robust tools for deployment. <br><br> **Choose between large and small language models** <br> - **LLM**:  designed for tasks that require deep reasoning, complex content generation, and extensive context understanding <br> - **SLM**: efficient and cost-effective, while still handling many common Natural Language Processing (NLP) tasks <br> **Focus on a modality, task, or tool** <br> - **embedding modesl**: onvert text into numerical representations and are used to improve search relevance by understanding semantic meaning.  <br> - often implemented in Retrieval Augmented Generation (RAG) scenarios to enhance recommendation engines by linking similar content. <br> **Specialize with regional and domain-specific models** <br> - Certain models are designed for specific languages, regions, or industries. These models can outperform general-purpose generative AI in their respective domains.<br><br> **Balance flexibility and performance with open versus proprietary models**<br> - Proprietary models are best for cutting-edge performance and enterprise use. <br> - Open-source models are best for flexibility and cost-efficiency. <br> - Open models give developers more control, allowing fine-tuning, customization, and local deployment.<br> **How do I select the best model for my use case?**<br> - Task type <br> - Precision: Is the base model good enough or do you need a fine-tuned model? <br> - Openness: Do you want to be able to fine-tune the model yourself? <br> - Deployment: Do you want to deploy the model locally, on a serverless endpoint, or do you want to manage the deployment infrastructure? <br> <br> - These benchmarks can help you in the initial exploration phase, but give little information on how the model would perform in your specific use case. <br> - **LIST OF CRITERIA** <br> - To evaluate how a selected model performs regarding your specific requirements, you can consider manual or automated evaluations. <br><br> **Considerations for scaping**<br> - Model deployment: Where will you deploy the model for the best balance of performance and cost? <br> - Model monitoring and optimization: How will you monitor, evaluate, and optimize model performance? <br> - Prompt management: How will you orchestrate and optimize prompts to maximize the accuracy and relevance of generated responses? <br> - Model lifecycle: How will you manage model, data, and code updates as part of an ongoing Generative AI Operations (GenAIOps) lifecycle? |
||[Deploy a model to an endpoint](https://learn.microsoft.com/en-us/training/modules/explore-models-azure-ai-studio/3-deploy-model)||- can integrate a language model with a chat application by deploying the model to an endpoint. <br> - **endpoint**: a specific URL where a deployed model or service can be accessed. <br><br> **Azure AI Foundry Deployment Options** <br> - Standard deployment:(recommended) Models are hosted in the Azure AI Foundry project resource <br> - Serverless compute: Models are hosted in Microsoft-managed dedicated serverless endpoints in an Azure AI Foundry hub project. <br> - Managed compute: Models are hosted in managed virtual machine images in an Azure AI Foundry hub project <br> - **TABLE WITH COMPARISON**|
||[Optimize model performance](https://learn.microsoft.com/en-us/training/modules/explore-models-azure-ai-studio/4-improve-model)||**Apply prompt patterns to optimize your model's output** <br> - **prompt engineering**: the process of designing and optimizing prompts to improve the model's performance <br><br> **Helpful patterns** <br> - Instruct the model to act as a persona.  <br> - Guide the model to suggest better questions.  <br> - Provide a template to generate output in a specific format.  <br> - Understand how a model reasons by asking it to reflect.  <br> - Add context to improve the accuracy of the model's output. <br> - **system prompt** sets the model's behavior and allows you to guide the model without exposing the end user to the instructions. <br> - Define the persona and add more detail to what you expect that persona to know or do to get tailored, context-driven responses. <br> - you can prompt the model to suggest clarifying questions to help you get a more targeted answer. <br> - When you want the model to generate output in a specific format, you can provide a template or structure in your prompt. <br> - You can also use a one-shot or few-shots approach by providing one or more examples to help the model identify a desired pattern. <br> - When you want the model to explain the reasoning behind its answers, you can ask the model to automatically reflect on its rationale and assumptions after providing a response. <br> - When you ask the model to define its reasoning, you use a technique called chain-of-thought to make it think step by step. <br> - When you want the model to focus on specific topics, you can specify the context to consider. <br> - You can specify the context by describing what it should or shouldn't include, and by connecting the model to data sources it should retrieve context from before generating an answer. <br><br> model optimization strategies<br> - Retrieval Augmented Generation (RAG): A technique that involves using a data source to provide grounding context to prompts. RAG can be a useful approach when you need the model to answer questions based on a specific knowledge domain or when you need the model to consider information related to events that occurred after the training data on which the model is based. <br> - Fine-tuning: A technique that involves extending the training of a foundation model by providing example prompts and responses that reflect the desired output format and style.<br> - Optimize for context (RAG): When the model lacks contextual knowledge and you want to maximize responses accuracy. <br> - Optimize the model (Fine-tuning): When you want to improve the response format, style, or speech by maximizing consistency of behavior. <br> - train a base language model on a dataset of example prompts and responses before integrating it in your application, with the result that the fine-tuned model will produce responses that are consistent with the examples in the fine-tuning training dataset. |
||[Deploy a chat with a language model](https://learn.microsoft.com/en-us/training/modules/explore-models-azure-ai-studio/5-exercise)||
