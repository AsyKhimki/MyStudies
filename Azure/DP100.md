<h1> Microsoft Certified: Azure Data Scientist Associate </h1>

**Reference**
1. [Study Guide](https://learn.microsoft.com/en-gb/credentials/certifications/resources/study-guides/dp-100)

<h2> 1. Design a machine learning solution </h2>

| Unit  | Topic   | Comments       |
| :---    | :---   | :---     |
| Design a data ingestion strategy for machine learning projects | [Identify your data source and format](https://learn.microsoft.com/en-gb/training/modules/design-data-ingestion-strategy-for-machine-learning-projects/2-identify-your-data-source-format) |  |
| | [Choose how to serve data to machine learning workflows](https://learn.microsoft.com/en-gb/training/modules/design-data-ingestion-strategy-for-machine-learning-projects/3-choose-how-serve-data-workflows) | - Store data separately from your compute => minimize costs, more flexible </br> - Which tool or service is best to store the data depends on the data you have and the service you use for model training.| 
| | [Design a data ingestion solution](https://learn.microsoft.com/en-gb/training/modules/design-data-ingestion-strategy-for-machine-learning-projects/4-solution) | - **Data ingestion pipeline**: a sequence of tasks that move and transform the data. </br> - **Azure Synapse Pipelines**: UI or JSON + SQL, Python, or R. </br> - **Azure Synapse Compute**: Serverless SQL pools, dedicated SQL pools, or Spark pools </br> - **Azure Databricks**: Code first, in notebooks (sql, R, Python) uses Spark clusters </br> - **Azure ML**: compute clusters, which automatically scale up and down when needed </br> - Pipeline: Designer, or by creating a collection of scripts</br> Comparison criteria </br> - Azure Synapse Analytics and Azure Databricks - more scalable </br> - All tasks within the same tool - Azure ML|
| | [Exercise: Design a data ingestion strategy](https://learn.microsoft.com/en-gb/training/modules/design-data-ingestion-strategy-for-machine-learning-projects/5-exercise) ||
| Design a machine learning model training solution | [Introduction](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-model-training-solution/1-introduction)||
|| [Identify machine learning tasks](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-model-training-solution/2-identify-tasks) | - See the list of common machine learning tasks |
|| [Choose a service to train a machine learning model](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-model-training-solution/3-choose-service-train) | - Which service you use depends on factors like: </br> - What are the differences|
|| [Decide between compute options](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-model-training-solution/4-decide-between-compute-options) | - should monitor compute utilization to know when to scale up or down to save on time and costs. </br> - CPU or GPU </br> - For smaller tabular datasets, CPU will be sufficient and cheaper to use </br> - Unscructured - GPU </br> - When processing your data and training your model takes a long time => potentially GPU </br> </br> - General purpose or memory optimized Spark </br> - Spark compute or clusters use the same sizing as virtual machines in Azure but distribute the workloads. </br> - size of compute in Azure Machine Learning is shown as the virtual machine size. The sizes follow the same naming conventions as Azure Virtual Machines. </br> - Monitor the compute utilization </br> - how long it takes to train the model and how much compute is used to execute your code. </br> - If training too long - maybe GPU? / Spark|
|| [Exercise: Design a model training strategy](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-model-training-solution/5-exercise) ||
| Design a model deployment solution | [Understand how model will be consumed](https://learn.microsoft.com/en-gb/training/modules/design-model-deployment-solution/2-understand-how-model-consumed)| - plan how you integrate the model, as it may affect how you train the model or what training data you use. </br> -  integrate the model, you need to deploy a model to an endpoint. </br> - **an endpoint** can be a web address that an application can call to get a message back.</br> - Endpoint options: real-time predictions, batch predictions </br> -  Real-time: score any new data as it comes in </br> - Batch: want the model to score new data in batches, and save the results as a file or in a database| 
|| [Decide on real-time or batch deployment](https://learn.microsoft.com/en-gb/training/modules/design-model-deployment-solution/3-decide-real-time-batch-deployment)| **frequency of scoring**: how often and how quickly you need the predictions to be generated. </br> - model's predictions are only consumed at certain times - batch "number of predictions" </br> **cost of compute** </br> - real-time or batch endpoint, you'll use different types of compute </br> - real-time predictions, you need compute that is always available and able to return the results (almost) immediately.  => Azure Container Instance (ACI) and Azure Kubernetes Service (AKS) </br> - continuously paying for the compute </br> -  batch predictions, you need compute that can handle a large workload </br> - By letting the workspace scale down an idle compute cluster, you can save significant costs. </br> - There are scenarios where you expect to need real-time predictions when batch predictions can be more cost-effective. </br> - Simpler models require less cost and time to generate predictions.|
|Design a machine learning operations solution| [Explore an MLOps architecture](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-operations-solution/2-explore-machine-learning-operations-solution-architecture)| - prepare the model and operationalize it, </br> - **environment** a collection of resources </br> - Organize Azure Machine Learning environments </br> - dev, pre-prod, and prod environment </br> - Having separate environments makes it easier to control access to resources. Each environment can then be associated with a separate Azure Machine Learning workspace. </br> - use one workspace for development and production, you have a smaller Azure footprint and less management overhead => cant separate access Design an MLOps architecture|
| | [Design for monitoring](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-operations-solution/3-design-monitoring)| - you'll want to monitor the model, the data, and the infrastructure to collect metrics that help you decide on any necessary next steps. </br> -  `MLflow` to train and track your machine learning models. </br> - monitor for any responsible artificial intelligence (AI) issues </br> - which performance metrics you want to monitor and what the benchmark for each metric should be </br> - Monitor the data </br> - historical data: there may be trends that change the profile of the data, making your model less accurate. </br> - change in data profiles between current and the training data is known as **data drift** </br> - retrain models as required to maintain predictive accuracy. </br> -  Monitor the infrastructure  </br> - minimize cost and optimize performance. By reviewing compute utilization, you know whether you can scale down your provisioned compute, or whether you need to scale out to avoid capacity constraints.|
| | [Design for retraining](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-operations-solution/4-design-retraining) | Two approaches to design for retraining </br> - Schedule </br> - Metric </br></br> Pre-requisite: </br> - prepare code for automation </br> - scripts instead of notebooks with parameters </br> - host the code in a central repository </br> - Automate your code => configure Azure Machine Learning </br> - Can trigger a job from another tool: Azure DevOps and GitHub (Actions), ML CLI extention|

<h2> 2. Explore and configure the Azure Machine Learning workspace </h2>

| Unit  | Topic   | Comments       |
| :---    | :---   | :---     |
| Explore Azure Machine Learning workspace resources and assets | [Create an Azure Machine Learning workspace](https://learn.microsoft.com/en-gb/training/modules/explore-azure-machine-learning-workspace-resources-assets/2-provision) |- Steps to create ML workspace</br> - 4 Options to create azure workspace: through azure porta, arm template, Azure Command Line Interface (CLI), Azure Machine Learning Python SDK.</br> - Screenshot of an Azure workspace</br> - Give access to the Azure Machine Learning workspace</br> - RBAC: three general built-in roles (owner contributor, reader)</br> - Azure Machine Learning roles: AzureML Data</br> - Scientist and AzureML Compute operator</br> - Tips to organize your workspace |
||[Identify Azure Machine Learning resources](https://learn.microsoft.com/en-gb/training/modules/explore-azure-machine-learning-workspace-resources-assets/3-identify-resources)|- Workspace: top-level resource for Azure Machine Learning. mind access</br> - Types of compute resources and their main use cases</br> - Compute instances:: dev env for notebooks</br> - Compute clusters / Kubernetes clusters: good for PROD due to autoscaling</br> - Serverless compute: good for training</br> - Datastores: references to Azure data services, connection info stored in keyvalut</br> - 4 automatically created datastores and what they store</br> - workspaceartifactstore: => azureml => compute and experiment logs of running jobs</br> - workspaceworkingdirectory: =>  file share of the Azure Storage</br> - workspaceblobstore: => Blob Storage => default data source</br> - can create datastores to connect to other Azure data services|
||[Identify Azure Machine Learning assets](https://learn.microsoft.com/en-gb/training/modules/explore-azure-machine-learning-workspace-resources-assets/4-identify-assets)|- Assets: models, Environments, data, components</br> - Formats: .pkl, MLModel format specify the name and version</br> - Compute: ensure that your code runs on any compute that is available to you (requirements.txt => env)</br> - Environments specify software packages, environment variables, and software settings to run scripts.</br> - Data assets refer to a specific file or folder.</br> - Create a data asset: specify the path to point to the file or folder, the name, the version. </br> - component: make it easier to share code</br> - need to specify: name, version, code, and environment</br> - can use components when creating pipelines|
||[Train models in the workspace](https://learn.microsoft.com/en-gb/training/modules/explore-azure-machine-learning-workspace-resources-assets/5-run-jobs)|- Use Automated Machine Learning.</br> - Run a notebook</br> - All files you clone or create in the notebooks section are stored in the file share of the Azure Storage account created with the workspace.</br> - Run a script as a job types of jobs depending on a workload</br> - "Command: Execute a single script.</br> - Sweep: Perform hyperparameter tuning when executing a single script.</br> - Pipeline: Run a pipeline consisting of multiple scripts or components."|
||[Exercise - Explore the workspace](https://learn.microsoft.com/en-gb/training/modules/explore-azure-machine-learning-workspace-resources-assets/6-exercise-explore-workspace)||
|Explore developer tools for workspace interaction|[Explore the studio](https://learn.microsoft.com/en-gb/training/modules/explore-developer-tools-for-workspace-interaction/2-explore-studio)|- Azure Machine Learning studio is a web portal, which provides an overview of all resources and assets available in the workspace.</br> - Access the studio + screenshot</br> - Your actions</br> - Author: Create new jobs to train </br> - Assets: Create and review assets you use when training </br> - Manage: Create and manage resources</br> - Use case: ideal for quick experimentation or when you want to explore your past jobs|
||[Explore the Python SDK](https://learn.microsoft.com/en-gb/training/modules/explore-developer-tools-for-workspace-interaction/3-explore-python-sdk)|- Install the Python SDK</br> - Connect to workspace</br> - Reference documentation links|
||[Explore the CLI](https://learn.microsoft.com/en-gb/training/modules/explore-developer-tools-for-workspace-interaction/4-explore-cli)|- advantages to using the Azure CLI with Azure Machine Learning</br> - Automation, Consistency, Integration with DevOps, CI/CD</br> - Install the Azure CLI</br> - Install the Azure Machine Learning extension</br> - [Useful cource:](https://learn.microsoft.com/en-us/training/paths/train-models-azure-machine-learning-cli-v2/)|
||[Exercise - Explore the developer tools](https://learn.microsoft.com/en-gb/training/modules/explore-developer-tools-for-workspace-interaction/5-exercise)||
|Work with environments in Azure Machine Learning| [Introduction](https://learn.microsoft.com/en-gb/training/modules/work-environments-azure-machine-learning/1-introduction) | - environments list and store the necessary packages that you can reuse across compute targets.|
||[Understand environments](https://learn.microsoft.com/en-gb/training/modules/work-environments-azure-machine-learning/2-understand-environments)| - When you create an Azure Machine Learning workspace, curated environments are automatically created and made available to you</br> - Creating and registering custom environments makes it possible to define consistent, reusable runtime contexts for your experiments - regardless of where the experiment script is run</br> - What is an environment in Azure Machine Learning?</br> - Azure Machine Learning builds environment definitions into Docker images and conda environments</br> - Commands to view all available environments within the Azure Machine Learning workspace, to view details of a specific environment|
||[Explore and use curated environments](https://learn.microsoft.com/en-gb/training/modules/work-environments-azure-machine-learning/3-explore-use-curated-environments)|- Curated environments are prebuilt environments for the most common machine learning workloads, available in your workspace by default. </br> - use the prefix AzureML</br> - scripts that use popular ML toolings</br> - command to retrieve the description and tags of a curated environment with the Python SDK</br> - Use a curated environment</br> - Test and troubleshoot a curated environment</br> - curated environments allow for faster deployment time,</br> - review the detailed error logs in the Outputs + logs tab of your job|
||[Create and use custom environments](https://learn.microsoft.com/en-gb/training/modules/work-environments-azure-machine-learning/4-create-use-custom-environments)|- can define an environment from a Docker image, a Docker build context, and a conda specification with Docker image.</br> - Create a custom environment from a Docker image</br> - Create a custom environment with a conda specification file</br> - When you need to include other packages or libraries in your environment, you can add a conda specification file to a Docker image when creating the environment.</br> - Use an environment|
||[Exercise - Work with environments](https://learn.microsoft.com/en-gb/training/modules/work-environments-azure-machine-learning/6-knowledge-check)||

<h2> 3. Experiment with Azure Machine Learning </h2>

| Unit  | Topic   | Comments       |
| :---    | :---   | :---     |
| Find the best classification model with Automated Machine Learning | [Introduction](https://learn.microsoft.com/en-gb/training/modules/find-best-classification-model-automated-machine-learning/1-introduction) | - AutoML allows you to try multiple preprocessing transformations and algorithms with your data to find the best machine learning model. </br> - AutoML experiment using the visual interface of Azure Machine Learning studio, the Azure command-line interface (CLI), or the Python software development kit (SDK).|
|| [Preprocess data and configure featurization](https://learn.microsoft.com/en-gb/training/modules/find-best-classification-model-automated-machine-learning/2-preprocess-data-configure-featurization)|- 1. create a data asset in Azure Machine Learning </br> - 2. create a MLTable data asset that includes the schema of the data </br> -  3. AutoML applies scaling and normalization to numeric data automatically </br> - Apply featurization, can be customized </br> -  get notified if AutoML has detected any issues with the data, like whether there are missing values or class imbalance.|
|| [Run an Automated Machine Learning experiment](https://learn.microsoft.com/en-gb/training/modules/find-best-classification-model-automated-machine-learning/3-run-job)| - The algorithms AutoML uses will depend on the task you specify. </br> - List of algorithms for classification </br> - You can choose to block individual algorithms from being selected (compliance or save time) </br> -  primary metric is the target performance metric for which the optimal model will be determined. </br> - Set the limits </br> - Set the training properties </br> - hen you use a compute cluster, you can have as many parallel trials as you have nodes </br> -  can exclude (or include) a subset of the available algorithms. </br> - an also choose whether you want to allow AutoML to use ensemble models. </br> - Code to submit and monitor|
||[Evaluate and compare models](https://learn.microsoft.com/en-gb/training/modules/find-best-classification-model-automated-machine-learning/4-evaluate-compare-models)| - data guardrails will automatically be applied too. list of guardrails for classification </br> - To explore a model even further, you can generate explanations for each model that has been trained. |
|| [Exercise - Find the best classification model with Automated Machine Learning](https://learn.microsoft.com/en-gb/training/modules/find-best-classification-model-automated-machine-learning/5-exercise)||
| Track model training in Jupyter notebooks with MLflow | [Configure MLflow for model tracking in notebooks](	https://learn.microsoft.com/en-gb/training/modules/track-model-training-jupyter-notebooks-mlflow/2-use-mlflow-model-tracking) | - MLflow is an open-source library for tracking and managing your machine learning experiments. </br> - MLflow Tracking is a component of MLflow that logs everything about the model you're training, such as parameters, metrics, and artifacts. </br> - Set up on Azure + locally | 
| | [Train and track models in notebooks](https://learn.microsoft.com/en-gb/training/modules/track-model-training-jupyter-notebooks-mlflow/3-train-models-notebooks) | - To group model training results, you'll use experiments. </br> -  Log results with MLflow </br> - Enable autologging: supports automatic logging for popular machine learning libraries </br> - When the job has completed, you can review all logged metrics in the studio. </br> - Use custom logging: log supplementary or custom material that isn't logged through autologging. </br> - Common functions used with custom logging are:|
|| [Exercise - Track model training](https://learn.microsoft.com/en-gb/training/modules/track-model-training-jupyter-notebooks-mlflow/4-exercise-track-model-training)||


<h2> 4. Optimize model training with Azure Machine Learning </h2>

| Unit  | Topic   | Comments       |
| :---    | :---   | :---     |
| Run a training script as a command job in Azure Machine Learning | [Convert a notebook to a script](https://learn.microsoft.com/en-gb/training/modules/run-training-script-command-job-azure-machine-learning/2-convert-notebook-script) | - recommendations when creating scripts to have production-ready code </br> - Remove nonessential code.</br> - Refactor your code into functions.</br> - Test your script in the terminal.</br> - How to navigate to the terminal? |
||[Run a script as a command job](https://learn.microsoft.com/en-gb/training/modules/run-training-script-command-job-azure-machine-learning/3-run-script-command-job)|- What parameters are needed to configure </br> - How the jobs are grupped|
||[Use parameters in a command job](https://learn.microsoft.com/en-gb/training/modules/run-training-script-command-job-azure-machine-learning/4-use-parameters-command-job)|- pass a parameter value to a script you want to run as a command job|
||[Exercise - Run a training script as a command job](https://learn.microsoft.com/en-gb/training/modules/run-training-script-command-job-azure-machine-learning/5-exercise-run-training-script-command-job)||
|Track model training with MLflow in jobs| [Introduction](https://learn.microsoft.com/en-gb/training/modules/train-models-training-mlflow-jobs/1-introduction)| - MLflow is an open-source platform that helps you to track model metrics and artifacts across platforms and is integrated with Azure Machine Learning </br> - can run training scripts locally or in the cloud and compare the results|
||[Track metrics with MLflow](https://learn.microsoft.com/en-gb/training/modules/train-models-training-mlflow-jobs/2-track-metrics-mlflow)|- Understand MLflow </br> -  two options to track machine learning jobs with MLflow: Before you can use either of these options, you need to set up the environment to use MLflow. </br> - Include MLflow in the environment</br> - Enable autologging</br> - Autologging logs parameters, metrics, and model artifacts without anyone needing to specify what needs to be logged.</br> - Log metrics with MLflow</br> - "Depending on the type of value you want to log, use the MLflow command to store the metric with the experiment run:"</br> - Submit the job|
| | [View metrics and evaluate models](https://learn.microsoft.com/en-gb/training/modules/train-models-training-mlflow-jobs/3-view-metrics-evaluate-models)| - View the metrics in the Azure Machine Learning studio</br> -  Retrieve runs and metrics with MLflow.</br> -  you can query the runs in a notebook by using MLflow</br> -  Retrieve runs (in a notebook)|
||[Exercise - Use MLflow to track training jobs](https://learn.microsoft.com/en-gb/training/modules/train-models-training-mlflow-jobs/4-exercise-use-mlflow-track-training-jobs)|- When a data scientist enables MLflow autologging, where can all model assets be found? |
|Perform hyperparameter tuning with Azure Machine Learning |[Introduction](https://learn.microsoft.com/en-gb/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/1-introduction)|In Azure Machine Learning, you can tune hyperparameters by submitting a script as a sweep job.|
||[Define a search space](https://learn.microsoft.com/en-gb/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/2-define-search-space)|- The set of hyperparameter values tried during hyperparameter tuning is known as the search space. </br> - How to define search space for descrete and continuous hyperparameters</br> - Defining a search space|
||[Configure a sampling method](https://learn.microsoft.com/en-gb/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/3-configure-sampling-method)| - Grid sampling: Tries every possible combination.</br> -  Random sampling: Randomly chooses values from the search space</br> -  Sobol: Adds a seed to random sampling to make the results reproducible.</br> -  Bayesian sampling: Chooses new values based on previous results.</br> -  can only be applied when all hyperparameters are discrete</br> -  Sobol is a type of random sampling that allows you to use a seed. => reproducible</br> -  "You can only use Bayesian sampling with choice, uniform, and quniform parameter expressions.|
| |[Conrigure early termination](https://learn.microsoft.com/en-gb/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/4-configure-early-termination)|- Can limit the number of trials</br> -  When to use an early termination policy depend on the search space and sampling method you're working with.</br> -  grid sampling method over a discrete search space => unnesessary most likely want to use an early termination policy when working with continuous hyperparameters and a random or Bayesian sampling method.</br> -  evaluation_interval: Specifies at which interval you want the policy to be evaluated. Every time the primary metric is logged for a trial counts as an interval.</br> -  delay_evaluation: Specifies when to start evaluating the policy. This parameter allows for at least a minimum of trials to complete without an early termination policy affecting them.</br> -  Two parameters to configure three options for early termination</br> -  Bandit policy: Uses a slack_factor (relative) or slack_amount(absolute). Any new model must perform within the slack range of the best performing model.</br> -  Median stopping policy: Uses the median of the averages of the primary metric. Any new model must perform better than the median.</br> - "Truncation selection policy: Uses a truncation_percentage, which is the percentage of lowest performing trials. Any new model must perform better than the lowest performing trials.</br> -  bandit policy to stop a trial if the target performance metric underperforms the best trial so far by a specified margin.</br> -  A median stopping policy abandons trials where the target performance metric is worse than the median of the running averages for all trials.</br> -  A truncation selection policy cancels the lowest performing X% of trials at each evaluation interval based on the truncation_percentage value you specify for X.|
||[Use a sweep job for hyperparameter tuning](https://learn.microsoft.com/en-gb/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/5-use-sweep-job-hyperparameter-tuning)|- Create a training script for hyperparameter tuning</br> - whtat the script mast</br> - Configure and run a sweep job</br> - [Monitor and review sweep jobs](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters#visualize-hyperparameter-tuning-jobs?azure-portal=true)|
||[Exercise - Run a sweep job](https://learn.microsoft.com/en-gb/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/6-exercise-run-sweep-job)||
| Run pipelines in Azure Machine Learning| [Introduction](https://learn.microsoft.com/en-gb/training/modules/run-pipelines-azure-machine-learning/1-introduction)||
||[Create components](https://learn.microsoft.com/en-gb/training/modules/run-pipelines-azure-machine-learning/2-create-components)|- two main reasons why you'd use components:</br> - create components when you're preparing your code for scale</br> - Components can be easily shared to other Azure Machine Learning users</br> - Create a component</br> - A component consists of three parts: load the component: To use components in a pipeline, you'll need the script and the YAML file</br> - Register the component: To make the components accessible to other users in the workspace, you can also register components to the Azure Machine Learning workspace|
||[Create a pipeline](https://learn.microsoft.com/en-gb/training/modules/run-pipelines-azure-machine-learning/3-create-pipeline)|- "a pipeline is a workflow of machine learning tasks in which each task is defined as a component.</br> - Each component can be run on a specific compute target, making it possible to combine different types of processing as required to achieve an overall goal.</br> - Build a pipeline|
||[Run a pipeline job](https://learn.microsoft.com/en-gb/training/modules/run-pipelines-azure-machine-learning/4-run-pipeline-job)|- Run a pipeline job</br> - Configure a pipeline job</br> - Troubleshoot a pipeline job</br> - Schedule a pipeline job</br> - A pipeline is ideal if you want to get your model ready for production. </br> - o automate the retraining of a model, you can schedule a pipeline.</br> - To delete a schedule, you first need to disable it:</br> - display names of the jobs triggered by the schedule|
||[Exercise - Run a pipeline job](https://learn.microsoft.com/en-gb/training/modules/run-pipelines-azure-machine-learning/5-exercise-run-pipeline-job)|- Incorrect. You need the RecurrenceTrigger class to create a schedule that runs at a regular interval.</br> - Correct. prep_data.outputs.output_data is the output of the step that prepares the data.|


<h2> 5. Manage and review models in Azure Machine Learning </h2>

| Unit  | Topic   | Comments       |
| :---    | :---   | :---     |
| Register an MLflow model in Azure Machine Learning   | [Log models with MLflow](https://learn.microsoft.com/en-gb/training/modules/register-mlflow-model-azure-machine-learning/2-log-mlflow-model)| - MLflow is an open source platform that streamlines machine learning deployment, regardless of the type of model you trained and the framework you used. </br> - Why use MLflow? </br> - MLflow standardizes the packaging of models, which means that an MLflow model can easily be imported or exported across different workflows.</br> - The MLmodel file contains the model's metadata, which allows for model traceability. </br> - MLflow allows you to log a model as an artifact, or as a model. </br> - [Difference between an artifcat and a model:](https://learn.microsoft.com/en-us/azure/machine-learning/concept-mlflow-models?view=azureml-api-2#the-mlmodel-format?azure-portal=true)</br> - Use autologging to log a model</br> - MLflow's autologging automatically logs parameters, metrics, artifacts, and the model you train.</br> - The framework you use to train your model is identified and included as the flavor of your model.</br> - Manually log a model</br> - The schemas of the expected inputs and outputs are defined as the signature in the MLmodel file. |
| | [Understand the MLflow model format](https://learn.microsoft.com/en-gb/training/modules/register-mlflow-model-azure-machine-learning/3-understand-mlflow-model-format)|- MLflow uses the MLModel format to store all relevant model assets in a folder or directory</br> -MLmodel file is the single source of truth about how the model should be loaded and used.</br> -A flavor is the machine learning library with which the model was created.</br> - Any MLflow python model can be loaded as a python_function mode</br> -There are two types of signatures:</br> -Column-based: used for tabular data with a pandas.Dataframe as inputs.</br> -Tensor-based: used for n-dimensional arrays or tensors (often used for unstructured data like text or images), with numpy.ndarray as inputs.</br> -the MLmodel file is created when you register the model|
||[Register an MLflow model](https://learn.microsoft.com/en-gb/training/modules/register-mlflow-model-azure-machine-learning/4-register-model)|- The model registry makes it easy to organize and keep track of your trained models.</br> - Registered models are identified by name and version</br> - There are three types of models you can register: </br> - Custom: Model type with a custom standard not currently supported by Azure Machine Learning.</br> - Triton: Model type for deep learning workloads. Commonly used for TensorFlow and PyTorch model deployments. </br> - MLflow: Model trained and tracked with MLflow. Recommended for standard use cases. </br> - To register an MLflow model, you can use the studio, the Azure CLI, or the Python SDK.|
||[Exercise - Log and register models with MLflow](https://learn.microsoft.com/en-gb/training/modules/register-mlflow-model-azure-machine-learning/5-exercise-register-mlflow-model)||
| Create and explore the Responsible AI dashboard for a model in Azure Machine Learning| [Indrocuction](https://learn.microsoft.com/en-gb/training/modules/manage-compare-models-azure-machine-learning/1-introduction)||
||[Understand Responsible AI](https://learn.microsoft.com/en-gb/training/modules/manage-compare-models-azure-machine-learning/2-understand-responsible-ai)| - Responsible Artificial Intelligence (Responsible AI) principles. </br> - Microsoft has listed five Responsible AI principles: </br> - Fairness and inclusiveness: Models should treat everyone fairly and avoid different treatment for similar groups. </br> - Reliability and safety: Models should be reliable, safe, and consistent. You want a model to operate as intended, handle unexpected situations well, and resist harmful manipulation. </br> - Privacy and security: Be transparent about data collection, use, and storage, to empower individuals with control over their data. Treat data with care to ensure an individual's privacy. </br> - Transparency: When models influence important decisions that affect people's lives, people need to understand how those decisions were made and how the model works. </br> - Accountability: Take accountability for decisions that models may influence and maintain human control.|
||[Create the Responsible AI dashboard](https://learn.microsoft.com/en-gb/training/modules/manage-compare-models-azure-machine-learning/3-create-responsible-dashboard)|- The Responsible AI dashboard allows you to pick and choose insights you need, to evaluate whether your model is safe, trustworthy, and ethical. </br> - To create a Responsible AI (RAI) dashboard, you need to create a pipeline by using the built-in components. </br> - Explore the Responsible AI components </br> - Add Explanation to RAI Insights dashboard: Interpret models by generating explanations. Explanations show how much features influence the prediction. </br> - Add Causal to RAI Insights dashboard: Use historical data to view the causal effects of features on outcomes. </br> - Add Counterfactuals to RAI Insights dashboard: Explore how a change in input would change the model's output. </br> - Add Error Analysis to RAI Insights dashboard: Explore the distribution of your data and identify erroneous subgroups of data. </br> - Build and run the pipeline to create the Responsible AI dashboard </br> - After you've trained and registered a model in the Azure Machine Learning workspace, you can create the Responsible AI </br> - "Using the Command Line Interface (CLI) extension for Azure Machine Learning. </br> - Using the Python Software Development Kit (SDK). </br> - Using the Azure Machine Learning studio for a no-code experience."|
|| [Evaluate the Responsible AI dashboard](https://learn.microsoft.com/en-gb/training/modules/manage-compare-models-azure-machine-learning/4-explore-responsible-dashboard)|- Depending on the components you selected, you can find the following insights in your Responsible AI dashboard:</br> - Error analysis</br> - Explanations</br> - Counterfactuals</br> - Causal analysis</br> - Error tree map: Allows you to explore which combination of subgroups results in the model making more false predictions.</br> - Error heat map: Presents a grid overview of a model's errors over the scale of one or two features.</br> - There are various statistical techniques you can use as model explainers. Most commonly, the mimic explainer trains a simple interpretable model on the same data and task. As a result, you can explore two types of feature importance:</br> - Aggregate feature importance: Shows how each feature in the test data influences the model's predictions overall.</br> - "Individual feature importance: Shows how each feature impacts an individual prediction.</br> - To explore how the model's output would change based on a change in the input, you can use counterfactuals.</br> - Causal analysis uses statistical techniques to estimate the average effect of a feature on a desired prediction. It analyzes how certain interventions or treatments may result in a better outcome, across a population or for a specific individual.</br> - There are three available tabs in the Responsible AI dashboard when including causal analysis:</br> - Aggregate causal effects: Shows the average causal effects for predefined treatment features (the features you want to change to optimize the model's predictions).</br> - Individual causal effects: Shows individual data points and allows you to change the treatment features to explore their influence on the prediction.</br> - reatment policy: Shows which parts of your data points benefit most from a treatment.|
||[Exercise - Explore the Responsible AI dashboard](https://learn.microsoft.com/en-gb/training/modules/manage-compare-models-azure-machine-learning/5-exercise-explore-responsible-dashboard)|


<h2> 6. Deploy and consume models with Azure Machine Learning </h2>

| Unit  | Topic   | Comments       |
| :---    | :---   | :---     |
| Deploy a model to a managed online endpoint| [Intro](https://learn.microsoft.com/en-gb/training/modules/deploy-model-managed-online-endpoint/1-introduction) | - To consume the model, you need to deploy it </br> - One way to deploy a model is to integrate it with a service that allows applications to request instant, or real-time, predictions for individual or small sets of data points|
| | [Explore managed online endpoints](https://learn.microsoft.com/en-gb/training/modules/deploy-model-managed-online-endpoint/2-explore-managed-online-endpoints)| - Real-time predictions </br> - An endpoint is an HTTPS endpoint to which you can send data, and which will return a response (almost) immediately. </br> - Azure Machine Learning, there are two types of online endpoints </br> - Managed online endpoints: Azure Machine Learning manages all the underlying infrastructure. </br> - Kubernetes online endpoints: Users manage the Kubernetes cluster which provides the necessary infrastructure. </br> - a managed online endpoint, you only need to specify the virtual machine (VM) type and scaling setting </br> - Deploy your model 4 things to specify to deploy your model to a managed online endpoint </br> - Blue/green deployment </br> - One endpoint can have multiple deployments. </br> - 90% of the traffic can go to the blue deployment*, and 10% of the traffic can go to the green deployment </br> - Create an endpoint|
||[Deploy your MLflow model to a managed online endpoint](https://learn.microsoft.com/en-gb/training/modules/deploy-model-managed-online-endpoint/3-deploy-your-mlflow-model-managed-online-endpoint)| - The easiest way to deploy a model to an online endpoint is to use an MLflow model and deploy it to a managed online endpoint. </br> - Deploy an MLflow model to an endpoint </br> - "don´t need to have the scoring script and environment." </br> - must have model files stored on a local path or with a registered model </br> - you also need to specify the compute configuration for the deployment|
|| [Deploy a model to a managed online endpoint](https://learn.microsoft.com/en-gb/training/modules/deploy-model-managed-online-endpoint/4-eploy-custom-model-managed-online-endpoint)|- "need to create the scoring script and define the environment necessary during inferencing.</br> - Deploy a model to an endpoint </br> - Pre-requisits</br> - Create the scoring script</br> - Create an environment</br> - Create the deployment</br> - can specify the compute configuration with two parameters (instance type, instance count)|
||[Test managed online endpoints](https://learn.microsoft.com/en-gb/training/modules/deploy-model-managed-online-endpoint/5-monitor-online-endpoints)| - Use the Azure Machine Learning studio</br> - List all endpointx</br> - Use the Azure Machine Learning Python SDK</br> - The response from the deployed model is a JSON collection with a prediction for each case that was submitted in the data.|
|| [Exercise - Deploy an MLflow model to an online endpoint](https://learn.microsoft.com/en-gb/training/modules/deploy-model-managed-online-endpoint/6-exercise-deploy-mlflow-model-online-endpoint)| - You should use Kubernetes online endpoint if you want to manage the underlying Kubernetes clusters.|
|Deploy a model to a batch endpoint| [Introduction](https://learn.microsoft.com/en-gb/training/modules/deploy-model-batch-endpoint/1-introduction) |- in machine learning, batch inferencing is used to asynchronously apply a predictive model to multiple cases and write the results to a file or database.|
|| [Understand and create batch endpoints](https://learn.microsoft.com/en-gb/training/modules/deploy-model-batch-endpoint/2-explore-batch-endpoints)|- Batch predictions</br> - An endpoint is an HTTPS endpoint that you can call to trigger a batch scoring job.</br> - can trigger the batch scoring job from another service, such as Azure Synapse Analytics or Azure Databricks.  => can integrate with existing pipeline</br> - uses a compute cluster to score multiple inputs</br> - Create a batch endpoint</br> - Use compute clusters for batch deployments</br> - The ideal compute to use for batch deployments is the Azure Machine Learning compute cluster|
|| [Deploy your MLflow model to a batch endpoint](https://learn.microsoft.com/en-gb/training/modules/deploy-model-batch-endpoint/3-deploy-your-mlflow-model-batch-endpoint)| - Register an MLflow model </br> - To avoid needed a scoring script and environment, an MLflow model needs to be registered in the Azure Machine Learning workspace </br> - Deploy an MLflow model to an endpoint</br> - need to specify how you want the batch scoring job to behave|
||[Deploy a custom model to a batch endpoint](https://learn.microsoft.com/en-gb/training/modules/deploy-model-batch-endpoint/4-deploy-custom-model-batch-endpoint)| - Create the scoring script: that reads the new data, loads the model, and performs the scoring. </br> - must include two functions: init(), run() </br> - Create an environment: can create an environment with a Docker image with Conda dependencies, or with a Dockerfile. Configure and create the deployment|
|| [Invoke and troubleshoot endpoints](https://learn.microsoft.com/en-gb/training/modules/deploy-model-batch-endpoint/5-monitor-batch-endpoints)| - When you invoke a batch endpoint, you trigger an Azure Machine Learning pipeline job.</br> - Trigger the batch scoring job </br> - Troubleshoot a batch scoring job|
|| [Exercise - Deploy an MLflow model to a batch endpoint](https://learn.microsoft.com/en-gb/training/modules/deploy-model-batch-endpoint/6-exercise-deploy-mlflow-model-batch-endpoint)| - The default deployment will be used to do the actual batch scoring when the endpoint is invoked.|
