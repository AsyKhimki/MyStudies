<h1> Microsoft Certified: Azure Data Scientist Associate </h1>

**Reference**
1. [Study Guide](https://learn.microsoft.com/en-gb/credentials/certifications/resources/study-guides/dp-100)

<h2> 1. Design a machine learning solution </h2>

| Unit  | Topic   | Section       | Notes  |
| :---    | :---   | :---     | :---     |
| Design a data ingestion strategy for machine learning projects | [Identify your data source and format](https://learn.microsoft.com/en-gb/training/modules/design-data-ingestion-strategy-for-machine-learning-projects/2-identify-your-data-source-format) | - Identify the data source </br> - Identify the data format </br> - Identify the desired data format| Steps for Data Scientist </br> 1. **Define the problem**: Decide on what the model should predict and when it's successful. </br> 2. **Get the data**: Find data sources and get access. </br> 3. **Prepare the data**: Explore the data. Clean and transform the data based on the model's requirements. <br> 4. **Train the model**: Choose an algorithm and hyperparameter values based on trial and error. </br> 5. **Integrate the model**: Deploy the model to an endpoint to generate predictions. </br> 6. **Monitor the model**: Track the model's performance. </br> </br> - Before being able to design the ETL or ELT process, you’ll need to identify your data source and data format.</br></br> Data Formats </br> - Tabular or structured data </br> - Semi-structured data </br> - Unstructured data: can't query the data in the database
| | [Choose how to serve data to machine learning workflows](https://learn.microsoft.com/en-gb/training/modules/design-data-ingestion-strategy-for-machine-learning-projects/3-choose-how-serve-data-workflows) | - Separate compute from storage </br> - Store data for model training workloads | Separate compute from storage </br> - ability to scale compute up or down </br> - can shut down compute without loosing the data </br> => it’s a best practice to store your data in one tool, which is separate from another tool you use to train your models.  </br> </br> Tools to train ML </br> - Azure Machine Learning </br> - Azure Databricks </br> - Azure Synapse Analytics </br> </br> Tools to store the data </br> - Azure Blob Storage </br> - Azure Data Lake Storage (Gen 2) </br> - Azure SQL Database| 
| | [Design a data ingestion solution](https://learn.microsoft.com/en-gb/training/modules/design-data-ingestion-strategy-for-machine-learning-projects/4-solution) | - Create a data ingestion pipeline </br> - Azure Synapse Analytics </br> - Azure Databricks </br> - Azure Machine Learning </br> - Design a data ingestion solution | - **Data ingestion pipeline**: a sequence of tasks that move and transform the data. </br>  It's a best practice to think about the architecture of a data ingestion solution before training model. </br></br> **Azure Synapse Pipelines**</br> - Pipeline definition: UI or JSON </br> - Data transformation: UI tool like mapping data flow or SQL, Python, or R. </br> - Compute resources: serverless SQL pools, dedicated SQL pools, or Spark pools. **Azure Databricks** </br> - Pipeline: in notebooks using SQL, R, Python </br> - Compute: Spark clusters </br></br> **Azure Machine Learning** </br> - Pipeline: Designer, or creating a collection of scripts </br> - Compute clusters, which automatically scale up and down when needed </br> - Pipeline: Designer, or by creating a collection of scripts </br></br> **Comparison criteria** </br> - Azure Synapse Analytics and Azure Databricks - more scalable </br> - All tasks within the same tool - Azure ML|
| | [Exercise: Design a data ingestion strategy](https://learn.microsoft.com/en-gb/training/modules/design-data-ingestion-strategy-for-machine-learning-projects/5-exercise) ||
| Design a machine learning model training solution | [Introduction](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-model-training-solution/1-introduction)||
|| [Identify machine learning tasks](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-model-training-solution/2-identify-tasks) | | Starting questions </br> -What the model’s output should be. </br> - What type of machine learning task you’ll use. </br> - What criteria makes a model successful. </br></br> See the list of common machine learning tasks </br> - Classification: Predict a categorical value. </br> - Regression: Predict a numerical value.</br> - Time-series forecasting: Predict future numerical values based on time-series data.</br> - Computer vision: Classify images or detect objects in images.</br> - Natural language processing (NLP): Extract insights from text.|
|| [Choose a service to train a machine learning model](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-model-training-solution/3-choose-service-train) | - Understand the difference between services | Important factors </br> - type of model </br> - need full control over model training. </br>- How much time you want to invest in model training. </br> - Which services are already within organization. </br> Which programming language </br></br> Commonly used services to train machine learning </br> - Azure Machine Learning </br> -  Azure Databricks Azure </br> - Synapse Analytics Azure AI Services</br> </br> General guidelines</br> - one of the customizable prebuilt models suits your requirements =>  Azure AI => save time and effort. </br> - want to keep all data-related (data engineering and data science) projects within the same service => Azure Synapse Analytics or Azure Databricks  </br> - need distributed compute for working with large datasets => Azure Synapse Analytics or Azure Databricks </br> - full control over model training and management => Azure Machine Learning or Azure Databricks </br> - Python is your preferred programming language =>  Azure Machine Learning  </br> - an intuitive user interface to manage ML lifecycle => Azure ML |
|| [Decide between compute options](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-model-training-solution/4-decide-between-compute-options) | - CPU or GPU </br> - General purpose or memory optimized </br> - Spark </br> - Monitor the compute utilization|**CPU or GPU** </br> - smaller tabular datasets => CPU: sufficient and cheaper </br> - unstructured => GPU </br> - processing data and training model takes a long time => GPU? </br> </br> **General purpose or memory optimized** </br> -**General purpose**: balanced CPU-to-memory ratio. </br> - testing and development with smaller datasets.</br> -**Memory optimized**: high memory-to-CPU ratio. </br> -Great for in-memory analytics, when have larger datasets or when working in notebooks. </br> </br> Spark </br> - Spark compute or clusters use the same sizing as virtual machines in Azure but distribute the workloads. </br> - size of compute in Azure ML is shown as the virtual machine size. </br>- sizes follow the same naming conventions as Azure VMs. </br></br> Monitor the compute utilization </br> - how long it takes to train the model? </br> how much compute is used to execute your code. </br> - If training too long - maybe GPU? / Spark|
|| [Exercise: Design a model training strategy](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-model-training-solution/5-exercise) ||
| Design a model deployment solution | [Understand how model will be consumed](https://learn.microsoft.com/en-gb/training/modules/design-model-deployment-solution/2-understand-how-model-consumed)| - Deploy a model to an endpoint </br> - Get real-time predictions </br> - Get batch predictions | **Definitions** </br> - integrate the model: deploy a model to an endpoint </br> - **an endpoint** can be a web address that an application can call to get a message back.</br> </br> - plan how you integrate the model, as it may affect how you train the model or what training data you use. </br></br> Endpoint options: </br> -  **Real-time**: score any new data as it comes in </br> - **Batch**: want the model to score new data in batches, and save the results as a file or in a database| 
|| [Decide on real-time or batch deployment](https://learn.microsoft.com/en-gb/training/modules/design-model-deployment-solution/3-decide-real-time-batch-deployment)| - Identify the necessary frequency of scoring </br> - Decide on the number of predictions </br> - Consider the cost of compute </br> - Decide on real-time or batch deployment | - model's predictions are only consumed at certain times => batch "number of predictions" </br></br>  **compute resources (cost)** </br> **real-time predictions** </br> - need compute that is always available and able to return the results (almost) immediately. => Azure Container Instance (ACI) and Azure Kubernetes Service (AKS) </br> - continuously paying for the compute </br></br>  **batch predictions** </br> - need compute that can handle a large workload </br> - scale down => can save significant costs. </br></br> - There are scenarios where expect to need real-time predictions when batch predictions can be more cost-effective. </br> - Simpler models require less cost and time to generate predictions.|
|Design a machine learning operations solution| [Explore an MLOps architecture](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-operations-solution/2-explore-machine-learning-operations-solution-architecture)| - Set up environments for development and production </br> - Organize Azure Machine Learning environments </br> - Design an MLOps architecture | Steps prepare the model and operationalize it </br> - Convert the model training to a robust and reproducible pipeline. </br> - Test the code and the model in a development environment. </br> - Deploy the model in a production environment. </br> - Automate the end-to-end process. </br></br>**environment** </br> - a collection of resources </br> - dev, pre-prod, and prod environment </br> - having separate environments makes it easier to control access to resources. </br>- Each environment can then be associated with a separate Azure Machine Learning workspace. </br> - use one workspace for development and production, you have a smaller Azure footprint and less management overhead => cant separate access Design an MLOps architecture </br> </br> Components of sample MLOps architecture</br> 1. **Setup**: Create all necessary Azure resources for the solution. </br>2. **Model development (inner loop)**: Explore and process the data to train and evaluate the model. </br> 3. Continuous integration: Package and register the model. </br> 4. **Model deployment** (outer loop): Deploy the model. </br> 5. **Continuous deployment**: Test the model and promote to production environment. </br> 6. **Monitoring**: Monitor model and endpoint performance.|
| | [Design for monitoring](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-operations-solution/3-design-monitoring)| - Monitor the model </br> - Monior the data </br> - Monitor the infrastructure | **Monitor the model** </br> - use `MLflow` to train and track your machine learning models. </br> - monitor for any responsible artificial intelligence (AI) issues </br> - decide which performance metrics you want to monitor and what the benchmark for each metric should be </br></br> **Monitor the data** </br> - historical data: there may be trends that change the profile of the data, making your model less accurate. </br> - change in data profiles between current and the training data is known as **data drift** </br> - retrain models as required to maintain predictive accuracy. </br></br> **Monitor the infrastructure**  </br> - minimize cost and optimize performance. </br> - compute might be the highest cost </br> - by reviewing compute utilization, know whether can scale down provisioned compute, need to scale out to avoid capacity constraints.|
| | [Design for retraining](https://learn.microsoft.com/en-gb/training/modules/design-machine-learning-operations-solution/4-design-retraining) | - Prepare your code </br> - Automate your code | Options to retrain </br> - Schedule </br> - Metric </br></br> Pre-requisite: </br> - prepare code for automation </br> - scripts instead of notebooks with parameters </br> - host the code in a central repository </br></br> Automate your code </br>- configure Azure Machine Learning </br> - can trigger a job from another tool: Azure DevOps and GitHub (Actions), ML CLI extention|

<h2> 2. Explore and configure the Azure Machine Learning workspace </h2>

| Unit  | Topic   | Section    | Notes    |
| :---    | :---   | :---     | :---     |
| Explore Azure Machine Learning workspace resources and assets | [Create an Azure Machine Learning workspace](https://learn.microsoft.com/en-gb/training/modules/explore-azure-machine-learning-workspace-resources-assets/2-provision) | - Understand the Azure Machine Learning service </br> - Create the workspace </br> - Give access to the Azure Machine Learning workspace </br> - Organize your workspaces | - The workspace is central place where you can work with all resources, assets available to train and deploy machine learning models. </br> - stores a history of all training jobs, including logs, metrics, outputs, and a snapshot of your code.  </br>- Steps to create ML workspace </br></br> Azure will automatically create other Azure resources within the same resource group to support the workspace </br> - **Azure Storage Account**store files and notebooks used in the workspace, to store metadata of jobs and models. </br> - **Azure Key Vault**: securely manage secrets such as authentication keys and credentials used by the workspace. </br> - **Application Insights**: To monitor predictive services in the workspace. </br> - **Azure Container Registry**: Created when needed to store images for Azure Machine Learning environments. </br></br> How to create Azure workspace </br> - Azure portal </br> - ARM template </br> -  Azure Command Line Interface (CLI)</br> - Azure Machine Learning Python SDK </br></br> **RBAC** </br> - **Owner**: full access to all resources, can grant access to others using access control. </br> - **Contributor**: full access to all resources, but can't grant access to others. </br> - **Reader**: Can view the resource, but isn't allowed to make any changes. </br></br> Azure Machine Learning roles </br> - **AzureML Data Scientist**: perform all actions within the workspace, except for creating or deleting compute resources, or editing the workspace settings. </br> - **AzureML Compute operator**: allowed to create, change, and manage access the compute resources within a workspace. |
||[Identify Azure Machine Learning resources](https://learn.microsoft.com/en-gb/training/modules/explore-azure-machine-learning-workspace-resources-assets/3-identify-resources)|- Create and manage the workspace </br> - Create and manage compute resources </br> - Create and manage datastores |   - **workspace**: top-level resource for Azure ML => mind access </br></br> Types of compute resources</br> - **compute instances**: similiar to vms, managed by workspace, ideal as dev environment for notebooks </br> - **compute clusters** on-demand clusters of CPU or GPU,  ideal for prod workload, as they can scale </br> - **Kubernetes clusters**: can attach AKS,  ideal to deploy trained machine learning models in prod scenarios.</br> - **serverless compute**: good for training </br> - **attached computes**: attach other Azure compute resources to the workspace (Azure Databricks, Synapse Spark pools). </br></br> Datastores  </br> - references to Azure data services, connection info stored in keyvalut</br> </br> automatically created datastores </br> - `workspaceartifactstore`: => azureml => compute and experiment logs of running jobs</br> - `workspaceworkingdirectory`: =>  file share of the Azure Storage</br> - `workspaceblobstore:` => Blob Storage => default data source </br> - `workspacefilestore`: Connects to the file share of the Azure Storage </br> - can create datastores to connect to other Azure data services|
||[Identify Azure Machine Learning assets](https://learn.microsoft.com/en-gb/training/modules/explore-azure-machine-learning-workspace-resources-assets/4-identify-assets)| - Create and manage models </br> - Create and manage environments </br> - Create and manage data </br> - Create and manage components| Examples of ML Assets </br> - models </br> - environments </br> - data</br> - components</br></br> **Models** </br> - Formats: `.pkl`, MLModel format specify the name and version</br> **Compute** </br> - ensure that your code runs on any compute that is available to you (requirements.txt => env)</br>**Environments** </br> - specify software packages, environment variables, and software settings to run scripts.</br>  **Data assets** </br>  - a specific file or folder. </br> - can use data assets to easily access data every time, without having to provide authentication</br> - create a data asset: specify the path to point to the file or folder, the name, the version. </br> **Component** </br> - reuse snippets of code from other projects.</br> - need to specify: name, version, code, and environment</br> - can use components when creating pipelines|
||[Train models in the workspace](https://learn.microsoft.com/en-gb/training/modules/explore-azure-machine-learning-workspace-resources-assets/5-run-jobs)| - Explore algorithms and hyperparameter values with Automated Machine Learning </br> - Run a notebook </br> -Run a script as a job | Options to train models with the Azure Machine Learning workspace: </br> - Use Automated Machine Learning. </br> - Run a Jupyter notebook. </br> Run a script as a job. </br></br> Run a notebook</br> - all files you clone or create in the notebooks section are stored in the file share of the Azure Storage</br></br> Run a script as a job types of jobs depending on a workload</br> - **command**: cxecute a single script.</br> - **sweep**: perform hyperparameter tuning when executing a single script.</br> - **pipeline**: consist of multiple scripts or components.|
||[Exercise - Explore the workspace](https://learn.microsoft.com/en-gb/training/modules/explore-azure-machine-learning-workspace-resources-assets/6-exercise-explore-workspace)||
|Explore developer tools for workspace interaction|[Explore the studio](https://learn.microsoft.com/en-gb/training/modules/explore-developer-tools-for-workspace-interaction/2-explore-studio)| - Access the studio |- Azure ML studio is a web portal, which provides an overview of all resources and assets available in the workspace.</br> - Access the studio + screenshot</br></br> What you can do in the studio </br> - **Author**: Create new jobs to train </br> - **Assets**: Create and review assets you use when training </br> - **Manage**: Create and manage resources</br></br> Use case </br> - ideal for quick experimentation or when you want to explore your past jobs </br> - when a pipeline job has failed, you can use the studio to navigate to the logs and review the error messages. |
||[Explore the Python SDK](https://learn.microsoft.com/en-gb/training/modules/explore-developer-tools-for-workspace-interaction/3-explore-python-sdk)| - Install the Python SDK</br> - Connect to workspace</br> - Use the reference documentation| To authenticate, you need the values of </br> -`subscription_id`: Your subscription ID. </br> -`resource_group`: The name of your resource group. </br> -`workspace_name`: The name of your workspace. </br></br> - Reference documentation links|
||[Explore the CLI](https://learn.microsoft.com/en-gb/training/modules/explore-developer-tools-for-workspace-interaction/4-explore-cli)| - Install the Azure CLI </br> - Install the Azure Machine Learning extension </br> - Work with the Azure CLI | Advantages to using the Azure CLI with Azure Machine Learning</br> - Automation, Consistency, Integration with DevOps, CI/CD</br> - [Useful source:](https://learn.microsoft.com/en-us/training/paths/train-models-azure-machine-learning-cli-v2/) </br> - [Reference documentation](https://learn.microsoft.com/en-us/cli/azure/ml/compute?view=azure-cli-latest) </br> - can also create the same compute target by first defining the configuration in a YAML file </br> - [yml resource specification](https://learn.microsoft.com/en-us/azure/machine-learning/reference-yaml-compute-aml?view=azureml-api-2)|
||[Exercise - Explore the developer tools](https://learn.microsoft.com/en-gb/training/modules/explore-developer-tools-for-workspace-interaction/5-exercise)||
|Work with environments in Azure Machine Learning| [Introduction](https://learn.microsoft.com/en-gb/training/modules/work-environments-azure-machine-learning/1-introduction) | | - **environments** list and store the necessary packages that you can reuse across compute targets.|
||[Understand environments](https://learn.microsoft.com/en-gb/training/modules/work-environments-azure-machine-learning/2-understand-environments)| - What is an environment in Azure Machine Learning? | - when create an Azure ML workspace, **curated environments** are automatically created and made available</br> - **custom environments** possible to define consistent, reusable runtime contexts for experiments, regardless of where the experiment script is run</br></br> - Azure ML builds environment definitions into Docker images and conda environments </br> When use an environment, Azure ML builds the environment on the Azure Container registry associated with the workspace. </br> Python code snippets </br> - view all available environments within the Azure ML workspace </br> - view details of a specific environment|
||[Explore and use curated environments](https://learn.microsoft.com/en-gb/training/modules/work-environments-azure-machine-learning/3-explore-use-curated-environments)| - Use a curated environment </br> - Test and troubleshoot a curated environment |- **curated environments**: prebuilt environments for the most common machine learning workloads, available in workspace by default. </br> - use the prefix AzureML</br> - scripts that use popular ML toolings</br> - Most commonly, you use environments ro run a script as a (command) job. /br> - curated environments allow for faster deployment time </br> - review the detailed error logs in the **Outputs + logs** tab of your job </br></br> Code snippets </br> - configure a command job with the Python SDK, which uses a curated environment including Scikit-Learn </br> - retrieve the description and tags of a curated environment with the Python SDK |
||[Create and use custom environments](https://learn.microsoft.com/en-gb/training/modules/work-environments-azure-machine-learning/4-create-use-custom-environments)| - Create a custom environment from a Docker image </br> - Create a custom environment with a conda specification file </br> - Use an environment | - can define an environment from a Docker image, a Docker build context, and a conda specification with Docker image.</br></br> Create a custom environment with a conda specification file</br> - When you need to include other packages or libraries in your environment, you can add a conda specification file to a Docker image when creating the environment. </br> - When you submit the job, the environment is built. The first time you use an environment, it can take 10-15 minutes to build the environment.  </br></br>Code snippets </br> - create an environment from a Docker image </br> - use the Azure ML base images to create an environment </br> - create an environment from a base Docker image and a conda specification file </br> - configure a command job with the Python SDK, which uses a curated environment including Scikit-Learn: |
||[Exercise - Work with environments](https://learn.microsoft.com/en-gb/training/modules/work-environments-azure-machine-learning/6-knowledge-check)||
|  Make data available in Azure Machine Learning | [Introduction](https://learn.microsoft.com/en-gb/training/modules/make-data-available-azure-machine-learning/)| | Learning objectives </br> - Access data by using Uniform Resource Identifiers (URIs). </br>-Connect to cloud data sources with datastores. </br> - Use data asset to access specific files or folders.| 
||[Understand URIs](https://learn.microsoft.com/en-gb/training/modules/make-data-available-azure-machine-learning/2-understand-uris)|- Understand URIs| - To find and access data in Azure Machine Learning, you can use Uniform Resource Identifiers (URIs). </br> - A **URI** references the location of your data </br> </br> Common protocols when working with data in the context of Azure Machine Learning </br> - `http(s)`: data storespublicly or privately in an Azure Blob Storage or publicly available http(s) location</br> - `abfs(s)`: data stores in an Azure Data Lake Storage Gen 2. </br> - `azureml`: Use for data stored in a datastore </br></br> - whenever possible, you should work with datastores and data assets in Azure Machine Learning (not to reveal sensitive info)</br> - A datastore is a reference to an existing storage account on Azure (Blob or data lake) - When you refer to the datastore , you won't need to authenticate as the connection information stored with the datastore will be used by Azure ML|
||[Create a datastore](https://learn.microsoft.com/en-gb/training/modules/make-data-available-azure-machine-learning/3-create-datastore)| - Understand types of datastores </br> - Use the built-in datastores </br> - Create a datastore </br> - Create a datastore for an Azure Blob Storage container | - datastores are abstractions for cloud data sources. They encapsulate the information needed to connect to data sources, and securely store this connection information so that you don’t have to code it in your scripts. </br>-Datastores allow you to easily connect to storage services without having to provide all necessary details every time you want to read or write data. </br> </br> Benefits of using data stores </br> - Provides easy-to-use URIs to your data storage.</br> - Facilitates data discovery within Azure Machine Learning. </br> - Securely stores connection information, without exposing secrets and keys to data scientists.</br></br> Authentication methods </br> - Credential-based: service principal, shared access signature (SAS) token or account key </br> - Identity based Microsoft Entra identity or managed identity. </br></br> Types of data stores </br> - Azure Blob Storage </br> - Azure File Share </br> - Azure Data Lake (Gen 2)</br></br> - Every workspace has four built-in datastores (two connecting to Azure Storage blob containers, and two connecting to Azure Storage file shares) </br></br> can create a datastore through</br> - GUI </br> Azure CLI </br> - Python SDK. </br></br> Code snipet </br> - create a datastore to connect to an Azure Blob Storage container with an account key </br> - ... with a SAS token|
||[Create a data asset](https://learn.microsoft.com/en-gb/training/modules/make-data-available-azure-machine-learning/4-create-data-asset)| - Understand data assets </br> - When to use data assets </br> - Create a URI file data asset </br> - Create a MLTable data asset | - To simplify getting access to the data, use data assets. </br> - **data assets**: references to where the data is stored, how to get access, and any other relevant metadata </br></br> </br> - can share and reuse data with other members of the team, they don't need to remember file locations. </br> - can seamlessly access data during model training (on any supported compute type) without worrying about connection strings or data paths </br> - You can version the metadata of the data asset.</br></br> Three main types of data assets </br> - **URI file**: Points to a specific file./br> - **URI folder**: Points to a folder.</br> - **MLTable**: Points to a folder or file, and includes a schema to read as tabular data.</br></br> - Data assets are most useful when executing machine learning tasks as Azure Machine Learning jobs </br> - in the code need to read the data before using it </br> - use a MLTable data asset when the schema of your data is complex or changes frequently </br> - Instead of changing how to read the data in every script that uses the data, you only have to change it in the data asset itself </br> - For certain features in Azure Machine Learning, like Automated Machine Learning, you need to use a MLTable data asset </br> - To define the schema, you can include a `MLTable` file in the same folder as the data you want to read </br> </br> Code</br> - Create and read an URI file data asset </br> - Create and read a URI folder data asset with the Python SDK </br> - Create and read a MLTable data asset with the Python SDK|
| Work with compute targets in Azure Machine Learning | [Choose appropriate compute targets](https://learn.microsoft.com/en-gb/training/modules/work-compute-resources-azure-machine-learning/2-compute-targets) || - **compute targets**: physical or virtual computers on which jobs are run.</br></br> Types of Compute </br> **Compute instance**: </br> - similiar to VM </br> - primarily to run notebooks </br> - ideal for experimentation.</br> **Compute clusters**: </br> - clusters of VM that automatically scale up or down </br> allow you to use parallel processing to distribute the workload & reduce time</br> **Kubernetes clusters**: </br> - more control over how the compute is configured and managed. </br> **Attached compute** </br>  - attach existing compute (Azure VMs or Azure Databricks)</br> - **Serverless compute**: A fully managed, on-demand compute you can use for training jobs. </br></br> Compute target for experimentation </br> - A notebook experience benefits most from a compute that is continuously running => compute instance </br> - Spark serverless compute to run Spark code in notebooks, if you want to make use of Spark's distributed compute power. </br></br> Production </br>  - want the compute target to be ready to handle large volumes of data </br> - compute cluster automatically scales up and down </br> - an alternative that you don't have to create and manage, you can use Azure Machine Learning's serverless compute </br></br> Deployment </br> - batch or real-time predictions? </br> - batch: compute clusters and Azure Machine Learning's serverless compute are ideal for pipeline jobs as they're on-demand and scalable </br> - real time: type of compute that is running continuously </br> - benefit from more lightweight compute </br> - Containers & Kubernetes clusters to manage the necessary compute to generate real-time predictions.|
||[Create and use a compute instance](https://learn.microsoft.com/en-gb/training/modules/work-compute-resources-azure-machine-learning/3-create-use-compute-instance)| - Create a compute instance with the Python SDK</br> - Assign a compute instance to a user </br> - Minimize compute time </br> - Use a compute instance| Create a compute instance in </br> - Azure Machine Learning studio </br> - Azure CLI </br> - Python SDK </br></br> - [Reference documentation](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.computeinstance?view=azure-python) </br> - When you need to create compute instances for multiple users, using a script allows you to create a consistent development environment for everyone. </br> - oto work with the compute instance, it needs to be assigned to you as a user. </br> - each instance can be assigned to 1 user (an't handle parallel workloads.)</br> - stop compute instance to save costs </br> - When a compute instance is assigned to you, can start and stop </br> - can add a schedule to the compute instance to start or stop at set times </br> - can configure a compute to automatically shut down when it has been idle for a set amount of time </br> - Easiest option to work with the compute instance is through the integrated notebooks experience in the Azure ML studio.|
||[Create and use a compute cluster](https://learn.microsoft.com/en-gb/training/modules/work-compute-resources-azure-machine-learning/4-create-use-compute-cluster)| - Create a compute cluster with the Python SDK</br> - Use a compute cluster |- in prod better to use scripts than notebooks </br></br> three parameters to consider when creating a cluster </br> - `size`: Specifies the virtual machine type of each node within the compute  cluster. </br> - `max_instances`: Specifies the maximum number of nodes </br> `tier`: Specifies whether your virtual machines are low priority or dedicated. </br></br> - [sizes of VMs](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/overview?tabs=breakdownseries%2Cgeneralsizelist%2Ccomputesizelist%2Cmemorysizelist%2Cstoragesizelist%2Cgpusizelist%2Cfpgasizelist%2Chpcsizelist) </br> Main scenarios when to use compute cluster </br> - Running a pipeline job you built in the Designer. </br> -  Running an Automated Machine Learning job </br> - Running a script as a job. </br></br> - allows you to train multiple models in parallel|

<h2> 3. Experiment with Azure Machine Learning </h2>

| Unit  | Topic   |  Section   | Notes |
| :---    | :---   | :---   | :---   |
| Find the best classification model with Automated Machine Learning | [Introduction](https://learn.microsoft.com/en-gb/training/modules/find-best-classification-model-automated-machine-learning/1-introduction) | | - `AutoML`: try multiple preprocessing transformations and algorithms to find the best machine learning model. </br> - `AutoML` use UI of Azure ML studio, the Azure CLI, or the Python SDK.|
|| [Preprocess data and configure featurization](https://learn.microsoft.com/en-gb/training/modules/find-best-classification-model-automated-machine-learning/2-preprocess-data-configure-featurization)| - Understand scaling and normalization </br> - Configure optional featurization| -  create a data asset in Azure Machine Learning </br> - AutoMl can only use a MLTable data asset that includes the schema of the data </br> - AutoML applies scaling and normalization to numeric data automatically </br> - By default, AutoML will perform featurization on your data </br> - after experiment get notified if AutoML has detected any issues with the data, like whether there are missing values or class imbalance. </br></br> Featurization that can be applied to AutoML </br> - Missing value imputation </br> - Categorical encoding </br> - Dropping high-cardinality features</br> - Feature engineering (for example, deriving individual date parts from DateTime features) </br> - can be customized |
|| [Run an Automated Machine Learning experiment](https://learn.microsoft.com/en-gb/training/modules/find-best-classification-model-automated-machine-learning/3-run-job)| - Restrict algorithm selection </br> - Configure an AutoML experiment </br> - Specify the primary metric </br> - Set the limits </br> - Submit an AutoML experiment | - [List of supported algorithms](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train?view=azureml-api-2&tabs=python#supported-algorithms?azure-portal=true) </br> - The algorithms AutoML uses will depend on the task you specify. </br> - List of algorithms for classification </br> - You can choose to block individual algorithms from being selected (compliance or save time) </br> -  primary metric is the target performance metric for which the optimal model will be determined.  </br> - when you use a compute cluster, you can have as many parallel trials as you have nodes </br> - can exclude (or include) a subset of the available algorithms. </br> - can also choose whether you want to allow AutoML to use ensemble models.</br></br> Several options to set limits to an AutoML</br> - `timeout_minutes`: Number of minutes after which the complete AutoML experiment is terminated.</br> - `trial_timeout_minutes`: Maximum number of minutes one trial can take.</br> - `max_trials`: Maximum number of trials, or models that will be trained.</br> - `enable_early_termination`: Whether to end the experiment if the score isn't improving in the short term.  </br></br> Code </br> - configure an AutoML experiment or job </br> - To retrieve the list of metrics available when you want to train a classification model </br> - submit an AutoML job </br> - monitor AutoML job runs in the Azure Machine Learning studio|
||[Evaluate and compare models](https://learn.microsoft.com/en-gb/training/modules/find-best-classification-model-automated-machine-learning/4-evaluate-compare-models)| - Explore preprocessing steps </br> - Retrieve the best run and its model | - In the Azure Machine Learning studio, you can select an AutoML experiment to explore its details. </br> - When enabled featurization for your AutoML experiment, data guardrails will automatically be applied too. </br> - You can review the technique applied in the list of models under Algorithm name. For </br> - To explore a model even further, you can generate explanations for each model that has been trained. </br> - In the Models tab of the AutoML experiment, can edit the columns to show other metrics in the same overview => can select models not only based on the primary metrics  </br></br> Each of data guardrails will show one of three possible states </br> - **Passed**: No problems were detected and no action is required.</br> - **Done**: Changes were applied to your data. </br> - **Alerted**: An issue was detected but couldn't be fixed. => should review the data to fix the issue.|
|| [Exercise - Find the best classification model with Automated Machine Learning](https://learn.microsoft.com/en-gb/training/modules/find-best-classification-model-automated-machine-learning/5-exercise)||
| Track model training in Jupyter notebooks with MLflow | [Configure MLflow for model tracking in notebooks](	https://learn.microsoft.com/en-gb/training/modules/track-model-training-jupyter-notebooks-mlflow/2-use-mlflow-model-tracking) | - Configure MLflow in notebooks </br> - Use Azure Machine Learning notebooks </br> - Use MLflow on a local device| - MLflow is an open-source library for tracking and managing your machine learning experiments. </br> - MLflow Tracking is a component of MLflow that logs everything about the model you're training, such as parameters, metrics, and artifacts.</br> - When you're running a notebook on a compute instance, MLflow is already configured, and ready to be used </br> - To use MLflow in notebooks in the Azure Machine Learning workspace, install the necessary libraries and set Azure ML as the tracking store. </br> - can create and edit notebooks within Azure ML or on a local device: => add MLFlow tracking url to a local notebook </br> - [MLFlow local set up](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow-cli-runs?view=azureml-api-2&tabs=interactive%2Ccli) | 
| | [Train and track models in notebooks](https://learn.microsoft.com/en-gb/training/modules/track-model-training-jupyter-notebooks-mlflow/3-train-models-notebooks) | - Create an MLflow experiment </br> - Log results with MLflow </br> - Enable autologging </br> - Use custom logging| - To group model training results, you'll use **experiments**. </br> - Enable autologging: supports automatic logging for popular machine learning libraries </br> - You can turn on autologging by using the autolog method for the framework you're using. </br> - When the job has completed, you can review all logged metrics in the studio. </br> - Use custom logging: log supplementary or custom material that isn't logged through autologging. </br></br> Common functions used with custom logging are</br>- `mlflow.log_param()`: single key-value parameter. (input) </br> - `mlflow.log_metric()`: single key-value metric. (any output you want to store with the run)</br> - `mlflow.log_artifact()`: Logs a file (plor). </br> - `mlflow.log_model()`: Logs a model. may include a custom signature, environment, and input examples.|
|| [Exercise - Track model training](https://learn.microsoft.com/en-gb/training/modules/track-model-training-jupyter-notebooks-mlflow/4-exercise-track-model-training)||


<h2> 4. Optimize model training with Azure Machine Learning </h2>

| Unit  | Topic   | Section   | Notes |
| :---    | :---   | :---     |  :---  |
| Run a training script as a command job in Azure Machine Learning | [Convert a notebook to a script](https://learn.microsoft.com/en-gb/training/modules/run-training-script-command-job-azure-machine-learning/2-convert-notebook-script) | </br> - Remove nonessential code.</br> - Refactor your code into functions.</br> - Test your script in the terminal. | - recommendations when creating scripts to have production-ready code </br> - how to navigate to the terminal? |
||[Run a script as a command job](https://learn.microsoft.com/en-gb/training/modules/run-training-script-command-job-azure-machine-learning/3-run-script-command-job)| - Configure and submit a command job | - To configure a command job with the Python SDK (v2), you'll use the command function </br> Parameters to configure: [the command function and all possible parameters](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml?view=azure-python) </br> - can monitor and review the job in the Azure ML studio </br> - jobs are grupped by experiment name </br></br> Code </br> - configure a command job </br> - submit a command job|
||[Use parameters in a command job](https://learn.microsoft.com/en-gb/training/modules/run-training-script-command-job-azure-machine-learning/4-use-parameters-command-job)| - Working with script arguments </br> - Passing arguments to a script |- use a library such as `argparse` to read arguments passed to the script </br> - want to pass a parameter value to a script you want to run as a command job, you'll specify the values in the command |
||[Exercise - Run a training script as a command job](https://learn.microsoft.com/en-gb/training/modules/run-training-script-command-job-azure-machine-learning/5-exercise-run-training-script-command-job)||
|Track model training with MLflow in jobs| [Introduction](https://learn.microsoft.com/en-gb/training/modules/train-models-training-mlflow-jobs/1-introduction)| | - MLflow is an open-source platform that helps you to track model metrics and artifacts across platforms and is integrated with Azure Machine Learning </br> - can run training scripts locally or in the cloud and compare the results </br> - can review model metrics and artifacts in the Azure ML workspace |
||[Track metrics with MLflow](https://learn.microsoft.com/en-gb/training/modules/train-models-training-mlflow-jobs/2-track-metrics-mlflow)| - Understand MLflow </br> - Include MLflow in the environment </br> - Enable autologging </br> - Log metrics with MLflow </br> - Submit the job | -can include MLflow in the scripts to track any parameters, metrics, and artifacts </br></br> two options to track machine learning jobs with MLflow: </br> - Enable autologging using mlflow.autolog() </br> - Use logging functions to track custom metrics using `mlflow.log_*` </br></br> - Before you can use either, need to set up the environment to use MLflow. </br> - Autologging logs parameters, metrics, and model artifacts without anyone needing to specify what needs to be logged. </br> - tracked parameters, metrics, and artifacts are stored with the job run. </br></br>  MLflow command to store the metric </br> - `mlflow.log_param()`: single key-value parameter (i.e. input parameter) </br> -`mlflow.log_metric()`: single key-value metric (number). any output to store with the run. </br> `mlflow.log_artifact()`: Log a file or a plot </br> - [MLFlow Documnentation](https://www.mlflow.org/docs/latest/tracking.html) |
| | [View metrics and evaluate models](https://learn.microsoft.com/en-gb/training/modules/train-models-training-mlflow-jobs/3-view-metrics-evaluate-models)| - View the metrics in the Azure ML studio </br> - Retrieve metrics with MLflow in a notebook </br> - Search all the experiments </br> - Retrieve runs | - View the metrics in the Azure Machine Learning studio</br> -  By default, experiments are ordered descending by start_time, which is the time the experiment was queued in Azure Machine Learning. </br> [Search experiments with MLFlow](https://mlflow.org/docs/latest/search-experiments.html) </br></br> Code </br> - get all the active experiments in the workspace using MLFlow (with / without archived) </br> - retrieve the metrics of a specific run </br> - look for a run with a specific combination in the hyperparameters|
||[Exercise - Use MLflow to track training jobs](https://learn.microsoft.com/en-gb/training/modules/train-models-training-mlflow-jobs/4-exercise-use-mlflow-track-training-jobs)|- When a data scientist enables MLflow autologging, where can all model assets be found? |
|Perform hyperparameter tuning with Azure Machine Learning |[Introduction](https://learn.microsoft.com/en-gb/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/1-introduction)| | In Azure Machine Learning, you can tune hyperparameters by submitting a script as a sweep job.|
||[Define a search space](https://learn.microsoft.com/en-gb/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/2-define-search-space)| - Discrete hyperparameters </br> - Continuous hyperparameters </br> - Defining a search space | - The set of hyperparameter values tried during hyperparameter tuning is known as the search space. </br> - create a dictionary with the appropriate parameter expression for each named hyperparameter.|
||[Configure a sampling method](https://learn.microsoft.com/en-gb/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/3-configure-sampling-method)|  - Grid sampling </br> - Random sampling </br> - Sobol </br> - Bayesian sampling| Three main sampling methids </br> - **Grid sampling**: every possible combination. (only discreete)</br> - **Random sampling**: Randomly chooses values from the search space</br> - **Sobol**: Adds a seed to random sampling to make the results reproducible.</br> - **Bayesian sampling**: Chooses new values based on previous results.</br> -  can only be applied when all hyperparameters are discrete</br> - can only use Bayesian sampling with choice, uniform, and quniform parameter expressions.|
| |[Conrigure early termination](https://learn.microsoft.com/en-gb/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/4-configure-early-termination)| - When to use an early termination policy </br> - Configure an early termination policy </br> - Bandit policy </br> - Median stopping policy </br> - Truncation selection policy | - Whether you want to use an early termination policy may depend on the search space and sampling method you're working with. </br> -  grid sampling method over a discrete search space => unnesessary </br> - most likely want to use an early termination policy when working with continuous hyperparameters and a random or Bayesian sampling method.</br></br> main parameters when you choose to use an early termination policy </br> - `evaluation_interval`: at which interval the policy to be evaluated. Every time the primary metric is logged for a trial counts as an interval.</br> -  `delay_evaluation`: Specifies when to start evaluating the policy. allows for at least a minimum of trials to complete without an early termination policy affecting them.</br></br> To determine the extent to which a model should perform better than previous trials, there are three options for early termination </br> - **Bandit policy**: `slack_factor` (relative) or `slack_amount`(absolute). Any new model must perform within the slack range of the best performing model </br> -  bandit policy to stop a trial if the target performance metric underperforms the best trial so far by a specified margin. </br> - **Median stopping policy**: Any new model must perform better than the median. </br> - A median stopping policy abandons trials where the target performance metric is worse than the median of the running averages for all trials </br> - **Truncation selection policy**: Uses a truncation_percentage, which is the percentage of lowest performing trials. Any new model must perform better than the lowest performing trials.</br> - i.e. the metric should not be in the worst 20% of the trials so far .</br> -  A truncation selection policy cancels the lowest performing X% of trials at each evaluation interval based on the truncation_percentage value you specify for X.|
||[Use a sweep job for hyperparameter tuning](https://learn.microsoft.com/en-gb/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/5-use-sweep-job-hyperparameter-tuning)| - Create a training script for hyperparameter tuning </br> - Configure and run a sweep job </br> - Monitor and review sweep jobs |To run a sweep job the script must: </br> - Include an argument for each hyperparameter you want to vary. </br> - Log the target performance metric with MLflow. </br></br> - To prepare the sweep job, you must first create a base command job that specifies which script to run and defines the parameters used by the script</br> - You can monitor sweep jobs in Azure Machine Learning studio. </br> - [Monitor and review sweep jobs](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters#visualize-hyperparameter-tuning-jobs?azure-portal=true)|
||[Exercise - Run a sweep job](https://learn.microsoft.com/en-gb/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/6-exercise-run-sweep-job)||
| Run pipelines in Azure Machine Learning| [Introduction](https://learn.microsoft.com/en-gb/training/modules/run-pipelines-azure-machine-learning/1-introduction)| | - Pipelines are key to implementing an effective Machine Learning Operations (MLOps|
||[Create components](https://learn.microsoft.com/en-gb/training/modules/run-pipelines-azure-machine-learning/2-create-components)| - Use a component </br> - Create a component </br> - Register a component |Reasons why you'd use components:</br> - prepare code for scale</br> - can be easily shared to other Azure ML users</br></br> A component consists of three parts </br>- **Metadata**: component's name, version, etc. </br>- Interface (inputs / outputs) </br>- Command, code and environment</br></br> To create the component need </br> - A script that contains the workflow you want to execute </br> - A YAML file to define the metadata, interface, and command, code, and environment of the component. </br> - load the component: to use components in a pipeline, you'll need the script and the YAML file</br> - To make the components accessible to other users in the workspace, you can also **register** components to the Azure Machine Learning workspace. </br> </br> Code </br>  - To create a component for the prep.py script, you'll need a YAML file prep.yml </br> - load the component  </br> - register a component |
||[Create a pipeline](https://learn.microsoft.com/en-gb/training/modules/run-pipelines-azure-machine-learning/3-create-pipeline)| - Build a pipeline| - a **pipeline** is a workflow of machine learning tasks in which each task is defined as a **component**.</br> - each component can be run on a specific compute target, making it possible to combine different types of processing as required to achieve an overall goal </br> can be arranged sequentially or in parallel </br> - A pipeline can be executed as a process by running the pipeline as a pipeline job.  </br> - An Azure ML pipeline is defined in a YAML file. </br></br> Code </br> - pipeline that first prepares the data, and then trains the model, you can use the following code </br> - To pass a registered data asset as the pipeline job input </br> - example of the yaml file|
||[Run a pipeline job](https://learn.microsoft.com/en-gb/training/modules/run-pipelines-azure-machine-learning/4-run-pipeline-job)| - Configure a pipeline job </br> - Run a pipeline job </br> - Schedule a pipeline job  | - A pipeline is ideal if you want to get your model ready for production. </br> - Azure ML studio creates a graphical representation of your pipeline </br> - to troubleshoot a failed pipeline, you can check the outputs and logs of the pipeline job and its child jobs.</br> - Pipelines are especially useful for automating the retraining of a machine learning model. (schedule a pipeline) </br> - To delete a schedule, you first need to disable it:</br> - display names of the jobs triggered by the schedule </br> </br> Code </br> -  review your pipeline configuration </br> - edit the pipeline configurations by specifying which parameters you want to change and the new value.  </br> - can set the default pipeline compute </br> - submit the pipeline job </br> - To delete a schedule, you first need to disable it|
||[Exercise - Run a pipeline job](https://learn.microsoft.com/en-gb/training/modules/run-pipelines-azure-machine-learning/5-exercise-run-pipeline-job)| | - Incorrect. You need the RecurrenceTrigger class to create a schedule that runs at a regular interval.</br> - Correct. prep_data.outputs.output_data is the output of the step that prepares the data.|


<h2> 5. Manage and review models in Azure Machine Learning </h2>

| Unit  | Topic   | Section  | Notes  |
| :---    | :---   | :---     |:---     |
| Register an MLflow model in Azure Machine Learning   | [Log models with MLflow](https://learn.microsoft.com/en-gb/training/modules/register-mlflow-model-azure-machine-learning/2-log-mlflow-model)| - Why use MLflow? </br> - Use autologging to log a model </br> -  Manually log a model </br> - Customize the signature | - MLflow is an open source platform that streamlines machine learning deployment, regardless of the type of model trained and the framework used. </br> - with MLflow model, can opt for the no-code deployment in Azure Machine LearningL </br> - MLflow standardizes the packaging of models, which means that an MLflow model can easily be imported or exported across different workflows.</br> - `MLmodel` file contains the model's metadata, which allows for model traceability. </br>  - can register models with MLflow by enabling autologging, or by using custom logging. </br> - MLflow allows you to log a model as an artifact, or as a model. </br> - [Difference between an artifcat and a model:](https://learn.microsoft.com/en-us/azure/machine-learning/concept-mlflow-models?view=azureml-api-2#the-mlmodel-format?azure-portal=true)</br> - Use autologging to log a model </br> - the model is logged when the `.fit()` </br> - MLflow's autologging automatically logs parameters, metrics, artifacts, and the model you train.</br> - Training framework is identified and included as the **flavor** of the model.</br> - For manual logging use autolog and set `log_models=False` + add it manually </br> - The **schemas** of the expected inputs and outputs are defined as the **signature** in the `MLmodel` file (JSON) </br> - model signature can be inferred from datasets or created manually by hand. </br> - to infer signature from training dataset and model predictions => use `infer_signature()` </br></br> Code </br> - To log a model with a signature that is inferred from your training dataset and model predictions, you can use `infer_signature()` </br> - can create the signature manually|
| | [Understand the MLflow model format](https://learn.microsoft.com/en-gb/training/modules/register-mlflow-model-azure-machine-learning/3-understand-mlflow-model-format)| - Understand the MLflow model format </br> - Explore the MLmodel file format </br> - Choose the flavor </br> - Configure the signature | - MLflow uses the MLModel format to store all relevant model assets in a folder or directory</br> -MLmodel file is the single source of truth about how the model should be loaded and used</br> - the MLmodel file is created when you register the model </br> - **flavor** is the machine learning library with which the model was created. </br> - each model flavor indicates how they want to persist and load models => MLModel format doesn't enforce a single serialization mechanism that all the models</br> - Any MLflow python model can be loaded as a python_function mode</br></br> Two types of signatures:</br> - **Column-based**: used for tabular data with a pandas.Dataframe as inputs.</br> - **Tensor-based**: used for n-dimensional arrays or tensors (often used for unstructured data like text or images), with numpy.ndarray as inputs</br></br> - If you want the signature to be different, you need to manually log the model.|
||[Register an MLflow model](https://learn.microsoft.com/en-gb/training/modules/register-mlflow-model-azure-machine-learning/4-register-model)| - Register an MLflow model | - The model registry makes it easy to organize and keep track of your trained models.</br> - Registered models are identified by name and version </br> - can add more metadata tags to more easily search for a specific model. </br></br> Three types of models</br> - **Custom**: Model type with a custom standard not currently supported by Azure ML.</br> - **Triton**: Model type for deep learning workloads. (TensorFlow and PyTorch model deployments). </br> - **MLflow**: trained and tracked with MLflow. Recommended for standard use cases.</br> </br> - To register an MLflow model, you can use the studio, the Azure CLI, or the Python SDK. </br> - All registered models are listed in the Models page of the Azure ML studio </br></br> Code </br> - train the model </br> - register the model|
||[Exercise - Log and register models with MLflow](https://learn.microsoft.com/en-gb/training/modules/register-mlflow-model-azure-machine-learning/5-exercise-register-mlflow-model)||
| Create and explore the Responsible AI dashboard for a model in Azure Machine Learning| [Indrocuction](https://learn.microsoft.com/en-gb/training/modules/manage-compare-models-azure-machine-learning/1-introduction)||
||[Understand Responsible AI](https://learn.microsoft.com/en-gb/training/modules/manage-compare-models-azure-machine-learning/2-understand-responsible-ai)| - Responsible Artificial Intelligence (Responsible AI) principles. </br> - Microsoft has listed five Responsible AI principles: </br> - Fairness and inclusiveness: Models should treat everyone fairly and avoid different treatment for similar groups. </br> - Reliability and safety: Models should be reliable, safe, and consistent. You want a model to operate as intended, handle unexpected situations well, and resist harmful manipulation. </br> - Privacy and security: Be transparent about data collection, use, and storage, to empower individuals with control over their data. Treat data with care to ensure an individual's privacy. </br> - Transparency: When models influence important decisions that affect people's lives, people need to understand how those decisions were made and how the model works. </br> - Accountability: Take accountability for decisions that models may influence and maintain human control.|
||[Create the Responsible AI dashboard](https://learn.microsoft.com/en-gb/training/modules/manage-compare-models-azure-machine-learning/3-create-responsible-dashboard)|- The Responsible AI dashboard allows you to pick and choose insights you need, to evaluate whether your model is safe, trustworthy, and ethical. </br> - To create a Responsible AI (RAI) dashboard, you need to create a pipeline by using the built-in components. </br> - Explore the Responsible AI components </br> - Add Explanation to RAI Insights dashboard: Interpret models by generating explanations. Explanations show how much features influence the prediction. </br> - Add Causal to RAI Insights dashboard: Use historical data to view the causal effects of features on outcomes. </br> - Add Counterfactuals to RAI Insights dashboard: Explore how a change in input would change the model's output. </br> - Add Error Analysis to RAI Insights dashboard: Explore the distribution of your data and identify erroneous subgroups of data. </br> - Build and run the pipeline to create the Responsible AI dashboard </br> - After you've trained and registered a model in the Azure Machine Learning workspace, you can create the Responsible AI </br> - "Using the Command Line Interface (CLI) extension for Azure Machine Learning. </br> - Using the Python Software Development Kit (SDK). </br> - Using the Azure Machine Learning studio for a no-code experience."|
|| [Evaluate the Responsible AI dashboard](https://learn.microsoft.com/en-gb/training/modules/manage-compare-models-azure-machine-learning/4-explore-responsible-dashboard)|- Depending on the components you selected, you can find the following insights in your Responsible AI dashboard:</br> - Error analysis</br> - Explanations</br> - Counterfactuals</br> - Causal analysis</br> - Error tree map: Allows you to explore which combination of subgroups results in the model making more false predictions.</br> - Error heat map: Presents a grid overview of a model's errors over the scale of one or two features.</br> - There are various statistical techniques you can use as model explainers. Most commonly, the mimic explainer trains a simple interpretable model on the same data and task. As a result, you can explore two types of feature importance:</br> - Aggregate feature importance: Shows how each feature in the test data influences the model's predictions overall.</br> - "Individual feature importance: Shows how each feature impacts an individual prediction.</br> - To explore how the model's output would change based on a change in the input, you can use counterfactuals.</br> - Causal analysis uses statistical techniques to estimate the average effect of a feature on a desired prediction. It analyzes how certain interventions or treatments may result in a better outcome, across a population or for a specific individual.</br> - There are three available tabs in the Responsible AI dashboard when including causal analysis:</br> - Aggregate causal effects: Shows the average causal effects for predefined treatment features (the features you want to change to optimize the model's predictions).</br> - Individual causal effects: Shows individual data points and allows you to change the treatment features to explore their influence on the prediction.</br> - reatment policy: Shows which parts of your data points benefit most from a treatment.|
||[Exercise - Explore the Responsible AI dashboard](https://learn.microsoft.com/en-gb/training/modules/manage-compare-models-azure-machine-learning/5-exercise-explore-responsible-dashboard)|


<h2> 6. Deploy and consume models with Azure Machine Learning </h2>

| Unit  | Topic   | Section   | Notes |
| :---    | :---   | :---     | :---     |
| Deploy a model to a managed online endpoint| [Intro](https://learn.microsoft.com/en-gb/training/modules/deploy-model-managed-online-endpoint/1-introduction) | | - To consume the model, you need to deploy it </br> - One way to deploy a model is to integrate it with a service that allows applications to request instant, or real-time, predictions for individual or small sets of data points|
| | [Explore managed online endpoints](https://learn.microsoft.com/en-gb/training/modules/deploy-model-managed-online-endpoint/2-explore-managed-online-endpoints)| - Real-time predictions </br> - Managed online endpoint  </br> - Deploy your model </br> - Blue/green deployment</br> - Create an endpoint|  - An **endpoint** is an HTTPS endpoint to which you can send data, and which will return a response (almost) immediately. </br> - Any data you send to the endpoint will serve as the input for the scoring script hosted on the endpoint. </br></br> In Azure Machine Learning, two types of online endpoints </br> - **Managed online endpoints**: Azure Machine Learning manages all the underlying infrastructure. </br> - **Kubernetes online endpoints**: Users manage the Kubernetes cluster which provides the necessary infrastructure. </br></br> - a managed online endpoint, you only need to specify the virtual machine (VM) type and scaling setting, everyhing else taken care of </br></br>To deploy your model to a managed online endpoint specify </br> - **Model assets** i.e. model pickle file, or a registered model in the Azure ML workspace. </br> -  **Scoring script** that loads the model.</br> - **Environment** (all necessary packages)</br> - **Compute configuration** including the needed compute size and scale settings to ensure you can handle the amount of requests the endpoint will receive. </br> - To deploy MLFlow models to an online endpoint, you don't need to provide a scoring script and environment, as both are automatically generated.</br> - **deployment**: a set of resources needed to host the model that performs the actual inferencing. </br> </br> - **Blue/green deployment**: one endpoint can have multiple deployments. </br> - 90% of the traffic can go to the blue deployment*, and 10% of the traffic can go to the green deployment </br> - can test the newer (green) model and re-direct more traffic to it </br> - [safe rollout](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-safely-rollout-online-endpoints?view=azureml-api-2&tabs=azure-cli) </br></br> To create an online endpoint use the `ManagedOnlineEndpoint` class, which requires </br> -`name`: (unique in region) Name of the endpoint.</br>- `auth_mode`: Use key for key-based authentication. </br></br> Code </br>- Create an endpoint|
||[Deploy your MLflow model to a managed online endpoint](https://learn.microsoft.com/en-gb/training/modules/deploy-model-managed-online-endpoint/3-deploy-your-mlflow-model-managed-online-endpoint)| - Deploy an MLflow model to an endpoint |- Teasiest way to deploy a model to an online endpoint is to use an MLflow model and deploy it to a managed online endpoint (automatically generate the scoring script and environment). </br></br> Deploy an MLflow model to an endpoint </br> - don´t need to have the scoring script and environment </br> - must have model files stored on a local path or with a registered model </br> - need to specify the compute configuration for the deployment (`instance_type`: Virtual machine (VM) size to use., `instance_count`) </br></br> Code </br> - deploy (and automatically register) the model </br> - route traffic to a specific deployment </br> - delete the endpoint and all associated deployments|
|| [Deploy a model to a managed online endpoint](https://learn.microsoft.com/en-gb/training/modules/deploy-model-managed-online-endpoint/4-eploy-custom-model-managed-online-endpoint)| - Deploy a model to an endpoint </br> - Create the scoring script </br> - Create an environment </br> - Create the deployment | To deploy a model to an endpoint: </br> - create an endpoint. </br> - Model files stored on local path or registered model. </br> - Create the scoring script</br> - Create an environment</br></br> The scoring script must have </br> - `init()`: Called when the service is  created or updated, to load and cache the model from the model registry </br> - `run()`: Called when new data is submitted to the service. </br></br> - deployment requires an execution environment in which to run the scoring script.</br> - can specify the compute configuration with two parameters (instance type, instance count)</br> - can create an environment with a Docker image with Conda dependencies, or with a Dockerfile </br></br> Code </br> - create an environment using a base Docker image, you can define the Conda dependencies in a conda.yml file </br> - to create the environment </br> - deploy the model|
||[Test managed online endpoints](https://learn.microsoft.com/en-gb/training/modules/deploy-model-managed-online-endpoint/5-monitor-online-endpoints)| - Use the Azure Machine Learning studio </br> - Use the Azure Machine Learning Python SDK | - can list all endpoints in the Azure ML studio, by navigating to the Endpoints page. </br> - can use the studio to test the endpoint.</br> - Typically, send data to deployed model in JSON format </br> - The response from the deployed model is a JSON collection with a prediction for each case that was submitted in the data.|
|| [Exercise - Deploy an MLflow model to an online endpoint](https://learn.microsoft.com/en-gb/training/modules/deploy-model-managed-online-endpoint/6-exercise-deploy-mlflow-model-online-endpoint)| - You should use Kubernetes online endpoint if you want to manage the underlying Kubernetes clusters.|
|Deploy a model to a batch endpoint| [Introduction](https://learn.microsoft.com/en-gb/training/modules/deploy-model-batch-endpoint/1-introduction) | | - in machine learning, batch inferencing is used to asynchronously apply a predictive model to multiple cases and write the results to a file or database.|
|| [Understand and create batch endpoints](https://learn.microsoft.com/en-gb/training/modules/deploy-model-batch-endpoint/2-explore-batch-endpoints)| - Batch predictions</br> - Create a batch endpoint</br> - Deploy a model to a batch endpoint </br> - Use compute clusters for batch deployments| - A batch endpoint allows to integrate the batch scoring with an existing data ingestion and transformation pipeline.</br> - uses a compute cluster to score multiple inputs </br> - To create a batch endpoint, use the `BatchEndpoint` class </br> - can deploy multiple models to a batch endpoint </br> - end-point names need to be unique within the region <</br> - The ideal compute to use for batch deployments is the Azure Machine Learning compute cluster </br></br>Code </br> - create an endpoint </br> - create a compute cluster, you can use the `AMLCompute` class.|
|| [Deploy your MLflow model to a batch endpoint](https://learn.microsoft.com/en-gb/training/modules/deploy-model-batch-endpoint/3-deploy-your-mlflow-model-batch-endpoint)| - Register an MLflow model </br> - Deploy an MLflow model to an endpoint | </br> - To avoid needed a scoring script and environment, an MLflow model needs to be registered in the Azure Machine Learning workspace </br> - `MLmodel` file describes how the model can be loaded and used. </br></br> Specify how you want the batch scoring job to behave </br> `instance_count`: Count of compute nodes to use for generating predictions.</br> - `max_concurrency_per_instance`: Maximum number of parallel scoring script runs per compute node.</br> - `mini_batch_size`: Number of files passed per scoring script run.</br> - `output_action`: What to do with the predictions: `summary_only` or `append_row`.</br> - `output_file_name`: File to which predictions will be appended, if you choose `append_row` for `output_action`.</br></br> Code </br> - register the model with the Python SDK</br> - deploy an MLflow model to a batch endpoint,|
||[Deploy a custom model to a batch endpoint](https://learn.microsoft.com/en-gb/training/modules/deploy-model-batch-endpoint/4-deploy-custom-model-batch-endpoint)| - Create the scoring script </br> - Create an environment </br> - Configure and create the deployment| - **scoring script**: a file that reads the new data, loads the model, and performs the scoring. </br> Scoring script must include two functions:</br> - `init()`: Called once at the beginning of the process, so use for any costly or common preparation like loading the model. </br> - `run()`: Called for each mini batch to perform the scoring. (should return a pandas DataFrame or an array/list)</br> - By default, the predictions will be written to one single file.</br> </br> - Create an environment: can create an environment with a Docker image with Conda dependencies, or with a Dockerfile. </br> - need to add the library `azureml-core` as it is required for batch deployments to work. </br> - [create a batch deployment](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.batchdeployment?view=azure-python)</br></br> Code </br> - A scoring script example </br> - create an environment using a base Docker image, you can define the Conda dependencies in a `conda.yaml` file </br> - create the environment </br> - onfigure and create the deployment with the `BatchDeployment` class|
|| [Invoke and troubleshoot endpoints](https://learn.microsoft.com/en-gb/training/modules/deploy-model-batch-endpoint/5-monitor-batch-endpoints)|  - Trigger the batch scoring job </br> - Troubleshoot a batch scoring job| - invoke a batch endpoint => trigger an Azure Machine Learning pipeline job </br> - can then use the registered data asset as input when invoking the batch endpoint with the Python SDK </br> - can monitor the run of the pipeline job in the Azure Machine Learning studio</br> -  troubleshoot the pipeline job => review its details and the outputs and logs of the pipeline job </br> **Outputs + logs tab** logs/user/ folder contains </br>- `job_error.txt`: Summarize the errors in script.</br>- `job_progress_overview.txt`: high-level information about the number of mini-batches processed so far.</br>- `job_result.txt`: Shows errors in calling the `init()` and `run()` function. </br></br> Code </br> - use the registered data asset as input when invoking the batch endpoint with the Python SDK |
|| [Exercise - Deploy an MLflow model to a batch endpoint](https://learn.microsoft.com/en-gb/training/modules/deploy-model-batch-endpoint/6-exercise-deploy-mlflow-model-batch-endpoint)| | - The default deployment will be used to do the actual batch scoring when the endpoint is invoked.|
