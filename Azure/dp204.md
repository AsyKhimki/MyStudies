<h1>Azure Data Engineer Associate </h1>

<h2> Get started with data engineering on Azure </h2>

| Unit  | Topic   | Section       | Notes  |
| :---    | :---   | :---     | :---     |
| Introduction to data engineering on Azure | [Introduction](https://learn.microsoft.com/en-gb/training/modules/introduction-to-data-engineering-azure/1-introduction?ns-enrollment-type=learningpath&ns-enrollment-id=learn.wwl.get-started-data-engineering)| | - data engineer is the primary role responsible for integrating, transforming, and consolidating data from various structured and unstructured data systems into structures that are suitable for building analytics solutions|
| | [What is data engineering](https://learn.microsoft.com/en-gb/training/modules/introduction-to-data-engineering-azure/2-what-data-engineering)|- Types of data </br> - Data operations </br> - Data integration </br> - Data transformation </br> - Data consolidation </br> -  Common languages| - PDF is unstructured data </br> - **Data integration**: establishing links between operational and analytical services and data sources to enable secure, reliable access to data across multiple systems </br> - **Data transformation**: transform operational data (ETL or ELT) to into suitable structure and format for analysis </br> - **Data consolidation**: the process of combining data that has been extracted from multiple data sources into a consistent structure - usually to support analytics and reporting|
| | [Important data engineering concepts](https://learn.microsoft.com/en-gb/training/modules/introduction-to-data-engineering-azure/4-common-patterns-azure-data-engineering)| - Operational and analytical data </br> - Streaming data  </br> - Data pipelines </br> - Data lakes </br> - Data warehouses </br> - Apache Spark| - **Operational data**: transactional data that is generated and stored by application </br> - **Analytical data**: data that has been optimized for analysis and reporting </br></br> - **Streaming data**: perpetual sources of data that generate data values in real-time, often relating to specific events. </br> - **Data pipelines**: orchestrate activities that transfer and transform data. </br> - **Data lake**: a storage repository that holds large amounts of data in native, raw formats. </br> - **Data warehouses**: store current and historical data in relational tables that are organized into a schema that optimizes performance for analytical queries. </br> - **Apache Spark**: parallel processing framework that takes advantage of in-memory processing and a distributed file storage|
|| [Data engineering in Microsoft Azure](https://learn.microsoft.com/en-gb/training/modules/introduction-to-data-engineering-azure/5-common-tooling-azure-data-engineering) || - Streaming data is captured in event broker services such as **Azure Event Hubs** </br></br> The core Azure technologies used to implement data engineering workloads include: </br> - Azure Synapse Analytics </br> - Azure Data Lake Storage Gen2</br> - Azure Stream Analytics</br> - Azure Data Factory </br> - Azure Databricks|
| Introduction to Azure Data Lake Storage Gen2 | [Introduction](https://learn.microsoft.com/en-gb/training/modules/introduction-to-azure-data-lake-storage/1-introduction)| | Data lake  </br> - provides file-based storage, usually in a distributed file system that supports high scalability for massive volumes of data </br> - can store structured, semi-structured, and unstructured files |
||[Understand Azure Data Lake Storage Gen2](https://learn.microsoft.com/en-gb/training/modules/introduction-to-azure-data-lake-storage/2-azure-data-lake-gen2)| - Benefits </br> - Hadoop compatible access </br> - Security </br> - Performance </br> - Data redundancy | **Data lake** </br> - a repository of data that is stored in its natural format, usually as blobs or files. </br> - combines a file system with a storage platform </br> </br> Benefits </br> -  designed to deal with this variety and volume of data at exabyte scale while securely handling hundreds of gigabytes of throughput </br> - can treat the data as if it's stored in a Hadoop Distributed File System (HDFS) </br> - can store the data in one place and access it through compute technologies including Azure Databricks, Azure HDInsight, and Azure Synapse Analytics  </br> - supports access control lists (ACLs) and Portable Operating System Interface (POSIX) permissions </br> -  can set permissions at a directory level or file level </br> - All data that is stored is encrypted at rest </br> - organizes the stored data into a hierarchy of directories and subdirectories, much like a file system => less resources needed for processing </br> - takes advantage of the Azure Blob replication models|
||[Enable Azure Data Lake Storage Gen2 in Azure Storage](https://learn.microsoft.com/en-gb/training/modules/introduction-to-azure-data-lake-storage/3-create-data-lake-account)||- a configurable capability of a StorageV2 (General Purpose V2) Azure Storage </br> - select the option to **Enable hierarchical** namespace in the Advanced|
||[Compare Azure Data Lake Store to Azure Blob storage](https://learn.microsoft.com/en-gb/training/modules/introduction-to-azure-data-lake-storage/4-azure-data-lake-and-blob-storage)||Azure Blob </br> - an store large amounts of unstructured ("object") data in a flat namespace within a blob container </br> - the blobs are stored as a single-level hierarchy in a flat namespace </br> - can access this data by using HTTP or HTTPs </br> - can use to archive rarely used data or to store website assets such as images and media </br></br> Azure Data Lake Storage Gen2  </br> - builds on blob storage and optimizes I/O of high-volume data by using a hierarchical namespace</br> - metadata: operations, such as directory renames and deletes, to be performed in a single atomic operation </br> - better storage and retrieval performance for an analytical use case and lowers the cost of analysis.|
||[Understand the stages for processing big data](https://learn.microsoft.com/en-gb/training/modules/introduction-to-azure-data-lake-storage/5-stages-for-processing-big-data)|| four stages for processing big data solutions </br> - Ingest </br> - Store </br> - Prep and train </br> - Model and serve |
||[Use Azure Data Lake Storage Gen2 in data analytics workloads](https://learn.microsoft.com/en-gb/training/modules/introduction-to-azure-data-lake-storage/6-use-cases) | </br> - Big data processing and analytics  </br> - Data warehousing </br> - Real-time data analytics</br> -  Data science and machine learning| - enabling technology for multiple data analytics use cases. </br> - Often, the data is staged in a data lake in order to facilitate distributed processing before being loaded into a relational data warehouse </br> - **data lakehouse** or **lake database**: data warehouse uses external tables to define a relational metadata layer over files in the data lake => can then support analytical queries for reporting and visualization </br> - Azure Data Lake Storage Gen 2 provides a highly scalable cloud-based data store for the volumes of data required in data science workloads.|
| Introduction to Azure Synapse Analytics | [Introduction](https://learn.microsoft.com/en-gb/training/modules/introduction-azure-synapse-analytics/1-introduction)||- Azure Synapse Analytics provides a single, cloud-scale platform that supports multiple analytical technologies; enabling a consolidated and integrated experience for data engineers, data analysts, data scientists, and other professionals who need to work with data.|
||[What is Azure Synapse Analytics](https://learn.microsoft.com/en-gb/training/modules/introduction-azure-synapse-analytics/2-what-happening-business)||Common types of analytical techniques (Gartner) </br> - **Descriptive analytics** - “What is happening in my business?” </br> - **Diagnostic analytics** - “Why is it happening?” </br> - Predictive analytics </br> - **Prescriptive analytics**: enable autonomous decision making based on real-time or near real-time analysis of data, using predictive analytics. |
|| [How Azure Synapse Analytics works](https://learn.microsoft.com/en-gb/training/modules/introduction-azure-synapse-analytics/3-how-works) |- Creating and using an Azure Synapse Analytics workspace </br> - Working with files in a data lake </br> - Ingesting and transforming data with pipelines </br> - Querying and manipulating data with SQL </br> - Processing and analyzing data with Apache Spark </br> - Exploring data with Data Explorer </br> - Integrating with other Azure data services| - A Synapse Analytics workspace defines an instance of the Synapse Analytics service in which can manage the services and data resources needed for your analytics solution|
